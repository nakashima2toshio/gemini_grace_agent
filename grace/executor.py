"""
GRACE Executor - è¨ˆç”»å®Ÿè¡Œã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ
ç”Ÿæˆã•ã‚ŒãŸè¨ˆç”»ã‚’é †æ¬¡å®Ÿè¡Œã—ã€çµæœã‚’ç®¡ç†
"""

import logging
import time
from typing import Dict, Optional, List, Callable, Any, Generator
from dataclasses import dataclass, field
from enum import Enum

from .schemas import (
    ExecutionPlan,
    PlanStep,
    StepResult,
    ExecutionResult,
    StepStatus,
    create_plan_id,
)
from .tools import ToolRegistry, ToolResult, create_tool_registry
from .config import get_config, GraceConfig
from .confidence import (
    ConfidenceCalculator,
    ConfidenceFactors,
    ConfidenceScore,
    LLMSelfEvaluator,
    ConfidenceAggregator,
    ActionDecision,
    InterventionLevel,
    create_confidence_calculator,
    create_llm_evaluator,
    create_confidence_aggregator,
    create_query_coverage_calculator,
)
from .intervention import (
    InterventionHandler,
    InterventionRequest,
    InterventionResponse,
    InterventionAction,
    create_intervention_handler,
)

# === Legacy Agent Integration ===
try:
    from services.agent_service import ReActAgent, get_available_collections_from_qdrant_helper
    LEGACY_AGENT_AVAILABLE = True
except ImportError:
    logger = logging.getLogger(__name__) # Ensure logger exists before warning
    logger.warning("Failed to import services.agent_service. Legacy agent execution will fail.")
    LEGACY_AGENT_AVAILABLE = False
# ================================

logger = logging.getLogger(__name__)


# =============================================================================
# å®Ÿè¡ŒçŠ¶æ…‹ç®¡ç†
# =============================================================================

@dataclass
class ExecutionState:
    """å®Ÿè¡ŒçŠ¶æ…‹ç®¡ç†"""

    plan: ExecutionPlan
    current_step_id: int = 0
    step_results: Dict[int, StepResult] = field(default_factory=dict)
    step_statuses: Dict[int, StepStatus] = field(default_factory=dict)
    overall_confidence: float = 0.0
    is_cancelled: bool = False
    is_paused: bool = False
    intervention_request: Optional[Any] = None  # InterventionRequest
    replan_count: int = 0
    max_replans: int = 3
    start_time: Optional[float] = None
    end_time: Optional[float] = None

    def __post_init__(self):
        """åˆæœŸåŒ–å¾Œã®å‡¦ç†"""
        # å…¨ã‚¹ãƒ†ãƒƒãƒ—ã‚’PENDINGã§åˆæœŸåŒ–
        for step in self.plan.steps:
            self.step_statuses[step.step_id] = StepStatus.PENDING

    def get_completed_outputs(self) -> Dict[int, str]:
        """å®Œäº†æ¸ˆã¿ã‚¹ãƒ†ãƒƒãƒ—ã®å‡ºåŠ›ã‚’å–å¾—"""
        return {
            step_id: result.output
            for step_id, result in self.step_results.items()
            if result.status == "success"
        }

    def get_completed_sources(self) -> List[str]:
        """å®Œäº†æ¸ˆã¿ã‚¹ãƒ†ãƒƒãƒ—ã®ã‚½ãƒ¼ã‚¹ã‚’å–å¾—"""
        sources = []
        for result in self.step_results.values():
            if result.status == "success" and result.sources:
                sources.extend(result.sources)
        return sources

    def can_replan(self) -> bool:
        """ãƒªãƒ—ãƒ©ãƒ³å¯èƒ½ã‹åˆ¤å®š"""
        return self.replan_count < self.max_replans and not self.is_cancelled

    def get_execution_time_ms(self) -> Optional[int]:
        """å®Ÿè¡Œæ™‚é–“ã‚’å–å¾—ï¼ˆãƒŸãƒªç§’ï¼‰"""
        if self.start_time is None:
            return None
        end = self.end_time or time.time()
        return int((end - self.start_time) * 1000)


# =============================================================================
# Executor ã‚¯ãƒ©ã‚¹
# =============================================================================

from .replan import ReplanOrchestrator, create_replan_orchestrator

class Executor:
    """è¨ˆç”»å®Ÿè¡Œã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆGRACEãƒã‚¤ãƒ†ã‚£ãƒ–å®Ÿè£…ï¼‰"""

    def __init__(
        self,
        config: Optional[GraceConfig] = None,
        tool_registry: Optional[ToolRegistry] = None,
        on_step_start: Optional[Callable[[PlanStep], None]] = None,
        on_step_complete: Optional[Callable[[StepResult], None]] = None,
        on_intervention_required: Optional[Callable[[str, Dict], Any]] = None,
        on_confidence_update: Optional[Callable[[ConfidenceScore, ActionDecision], None]] = None,
        on_replan: Optional[Callable[[str, int], None]] = None,
        replan_orchestrator: Optional[ReplanOrchestrator] = None,
        enable_replan: bool = True,
    ):
        self.config = config or get_config()

        # ToolRegistryï¼ˆæŒ‡å®šãŒãªã‘ã‚Œã°ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆä½œæˆï¼‰
        self.tool_registry = tool_registry or create_tool_registry(config=self.config)

        # Confidenceé–¢é€£ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆï¼ˆPhase 2ï¼‰
        self.confidence_calculator = create_confidence_calculator(config=self.config)
        self.llm_evaluator = create_llm_evaluator(config=self.config)
        self.query_coverage_calculator = create_query_coverage_calculator(config=self.config)
        self.confidence_aggregator = create_confidence_aggregator(config=self.config)

        # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
        self.on_step_start = on_step_start
        self.on_step_complete = on_step_complete
        self.on_intervention_required = on_intervention_required
        self.on_confidence_update = on_confidence_update
        self.on_replan = on_replan  # ãƒªãƒ—ãƒ©ãƒ³ç™ºç”Ÿæ™‚ã®ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯

        # InterventionHandlerï¼ˆPhase 3ï¼‰
        self.intervention_handler = create_intervention_handler(
            config=self.config,
            on_notify=self._handle_intervention_notify,
            on_confirm=self._handle_intervention_confirm,
            on_escalate=self._handle_intervention_escalate,
        )

        # ReplanOrchestratorï¼ˆPhase 4ï¼‰
        if replan_orchestrator is not None:
            self.replan_orchestrator = replan_orchestrator
        elif enable_replan:
            self.replan_orchestrator = create_replan_orchestrator(config=self.config)
        else:
            self.replan_orchestrator = None

        # ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã®ConfidenceScoreã‚’ä¿æŒ
        self.step_confidence_scores: Dict[int, ConfidenceScore] = {}

        replan_status = "enabled" if self.replan_orchestrator else "disabled"
        logger.info(
            f"Executor (GRACE Native) initialized: "
            f"tools={self.tool_registry.list_tools()}, replan={replan_status}"
        )

    def execute_plan_generator(
        self,
        plan: ExecutionPlan,
        state: Optional[ExecutionState] = None
    ) -> Generator[ExecutionState, None, ExecutionResult]:
        """
        è¨ˆç”»ã‚’ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã«å®Ÿè¡Œï¼ˆã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ç‰ˆï¼‰
        UIãªã©ã§é€²æ—ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ è¡¨ç¤ºã™ã‚‹ãŸã‚ã«ä½¿ç”¨
        Args:
            plan: å®Ÿè¡Œã™ã‚‹è¨ˆç”»
            state: æ—¢å­˜ã®çŠ¶æ…‹ï¼ˆå†é–‹æ™‚ãªã©ã«æŒ‡å®šï¼‰
        Yields:
            ExecutionState: å„ã‚¹ãƒ†ãƒƒãƒ—å®Œäº†å¾Œã®çŠ¶æ…‹
        Returns:
            ExecutionResult: æœ€çµ‚å®Ÿè¡Œçµæœ
        """
        logger.info(f"Executing plan (generator): {plan.plan_id}, steps={len(plan.steps)}")

        # å—ã‘å–ã£ãŸãƒ—ãƒ©ãƒ³å†…å®¹ã‚’ãƒ­ã‚°å‡ºåŠ›
        logger.info(f"Received Execution Plan in Executor (generator):\n{plan.model_dump_json(indent=2)}")

        # å®Ÿè¡ŒçŠ¶æ…‹ã‚’åˆæœŸåŒ–ï¼ˆæœªæŒ‡å®šã®å ´åˆï¼‰
        if state is None:
            state = ExecutionState(plan=plan)
            state.start_time = time.time()
            
        try:
            # å„ã‚¹ãƒ†ãƒƒãƒ—ã‚’é †æ¬¡å®Ÿè¡Œ
            # æ³¨: ãƒªãƒ—ãƒ©ãƒ³ãªã©ã§ã‚¹ãƒ†ãƒƒãƒ—æ•°ãŒå¢—æ¸›ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ç®¡ç†ãŒå¿…è¦
            # ã“ã“ã§ã¯ç°¡æ˜“çš„ã«ã€ç¾åœ¨ã®ã‚¹ãƒ†ãƒƒãƒ—IDä»¥é™ã‚’å®Ÿè¡Œã™ã‚‹ãƒ­ã‚¸ãƒƒã‚¯
            
            # å®Ÿè¡Œã™ã¹ãã‚¹ãƒ†ãƒƒãƒ—ã®ãƒªã‚¹ãƒˆã‚’å–å¾—ï¼ˆç¾åœ¨ã®è¨ˆç”»ã«åŸºã¥ãï¼‰
            # æ—¢ã«å®Œäº†ã—ã¦ã„ã‚‹ã‚¹ãƒ†ãƒƒãƒ—ã¯ã‚¹ã‚­ãƒƒãƒ—
            steps_to_execute = [
                s for s in plan.steps 
                if state.step_statuses.get(s.step_id) != StepStatus.SUCCESS
            ]
            
            for step in steps_to_execute:
                # çŠ¶æ…‹æ›´æ–°: ç¾åœ¨ã®ã‚¹ãƒ†ãƒƒãƒ—ID
                state.current_step_id = step.step_id
                
                # ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒã‚§ãƒƒã‚¯
                if state.is_cancelled:
                    logger.info("Execution cancelled")
                    break

                # ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯
                if not self._check_dependencies(step, state):
                    logger.warning(f"Step {step.step_id}: Dependencies not met, skipping")
                    state.step_statuses[step.step_id] = StepStatus.SKIPPED
                    yield state
                    continue

                # ã‚¹ãƒ†ãƒƒãƒ—é–‹å§‹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
                state.step_statuses[step.step_id] = StepStatus.RUNNING
                if self.on_step_start:
                    self.on_step_start(step)
                
                # ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œ
                # _execute_step ã¯ StepResult ã¾ãŸã¯ Generator[Any, None, StepResult] ã‚’è¿”ã™å¯èƒ½æ€§ãŒã‚ã‚‹
                step_execution = self._execute_step(step, state)
                
                result = None
                if isinstance(step_execution, Generator):
                    # ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã®å ´åˆã¯ã‚¤ãƒ™ãƒ³ãƒˆã‚’ä¸­ç¶™ã—ã€æœ€çµ‚çµæœ(return value)ã‚’å–å¾—
                    # yield from ã¯ return value ã‚’è¿”ã™
                    result = yield from step_execution
                else:
                    # ç›´æ¥çµæœãŒè¿”ã£ã¦ããŸå ´åˆ
                    result = step_execution

                # çµæœã‚’ä¿å­˜
                state.step_results[step.step_id] = result
                state.step_statuses[step.step_id] = (
                    StepStatus.SUCCESS if result.status == "success" else StepStatus.FAILED
                )

                # ã‚¹ãƒ†ãƒƒãƒ—å®Œäº†ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
                if self.on_step_complete:
                    self.on_step_complete(result)

                # ä¿¡é ¼åº¦ã«åŸºã¥ãä»‹å…¥ãƒã‚§ãƒƒã‚¯ (Phase 3)
                if step.step_id in self.step_confidence_scores:
                    confidence_score = self.step_confidence_scores[step.step_id]
                    action_decision = self.confidence_calculator.decide_action(confidence_score)
                    
                    # CONFIRM ã¾ãŸã¯ ESCALATE ã®å ´åˆã¯ä¸€æ™‚åœæ­¢
                    if action_decision.level in [InterventionLevel.CONFIRM, InterventionLevel.ESCALATE]:
                        logger.info(f"Pausing for intervention: {action_decision.level} (Step {step.step_id})")
                        
                        state.is_paused = True
                        
                        # ä»‹å…¥ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’ä½œæˆ
                        req_type = "confirm" if action_decision.level == InterventionLevel.CONFIRM else "escalate"
                        message = f"ä¿¡é ¼åº¦ãŒä½ã„ãŸã‚ç¢ºèªãŒå¿…è¦ã§ã™ ({confidence_score.score:.2f})"
                        if action_decision.reason:
                            message += f"\nç†ç”±: {action_decision.reason}"

                        # InterventionRequestã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆ
                        state.intervention_request = InterventionRequest(
                            level=action_decision.level,
                            step_id=step.step_id,
                            message=message,
                            reason=action_decision.reason,
                            confidence_score=confidence_score.score,
                            plan=plan
                        )
                        
                        # Yield: ä¸€æ™‚åœæ­¢çŠ¶æ…‹ã‚’é€šçŸ¥
                        yield state
                        
                        # ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã‚’çµ‚äº†ï¼ˆå†é–‹æ™‚ã¯æ–°ã—ã„ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã‚’ä½œæˆï¼‰
                        return self._create_execution_result(state)

                    # é€šçŸ¥ã®ã¿ï¼ˆSILENT/NOTIFYï¼‰
                    self._handle_intervention_if_needed(action_decision, step, state)

                # Yield: ã‚¹ãƒ†ãƒƒãƒ—å®Œäº†çŠ¶æ…‹ã‚’é€šçŸ¥
                yield state

                # ask_user ã®å ´åˆã®å‡¦ç†ï¼ˆæ—¢å­˜ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
                if step.action == "ask_user" and result.status == "success":
                     # ...æ—¢å­˜ã®ask_userå‡¦ç†...
                     pass

                # å¤±æ•—æ™‚ã®ãƒªãƒ—ãƒ©ãƒ³
                if result.status == "failed" and self.replan_orchestrator:
                    replan_result = self.replan_orchestrator.handle_step_failure(
                        step_result=result,
                        current_plan=plan,
                        completed_results=state.step_results,
                        replan_count=state.replan_count
                    )
                    if replan_result and replan_result.success and replan_result.new_plan:
                        logger.info(f"Replanning: {replan_result.reason}")
                        state.replan_count += 1
                        
                        # æ–°ã—ã„è¨ˆç”»ã«å·®ã—æ›¿ãˆ
                        # Generatorã‚’å†å¸°å‘¼ã³å‡ºã—ã™ã‚‹ã‹ã€ãƒ«ãƒ¼ãƒ—ã‚’å†æ§‹æˆã™ã‚‹å¿…è¦ãŒã‚ã‚‹
                        # ã“ã“ã§ã¯ã€æ–°ã—ã„è¨ˆç”»ã§å†å¸°çš„ã«Generatorã‚’ä½œæˆã—ã€ãã®å€¤ã‚’Yieldã™ã‚‹
                        state.plan = replan_result.new_plan
                        # å†å¸°å‘¼ã³å‡ºã—
                        yield from self.execute_plan_generator(replan_result.new_plan, state)
                        # å†å¸°ã‹ã‚‰æˆ»ã£ãŸã‚‰çµ‚äº†ï¼ˆæ–°ã—ã„è¨ˆç”»ãŒå®Œäº†ã—ã¦ã„ã‚‹ãŸã‚ï¼‰
                        return self._create_execution_result(state)

            # å…¨ä½“ã®ä¿¡é ¼åº¦ã‚’è¨ˆç®—
            state.overall_confidence = self._calculate_overall_confidence(state)
            state.end_time = time.time()

            # æœ€çµ‚çµæœ
            return self._create_execution_result(state)

        except Exception as e:
            logger.error(f"Execution failed: {e}", exc_info=True)
            state.end_time = time.time()
            # ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚çµæœã‚’è¿”ã™
            return ExecutionResult(
                plan_id=plan.plan_id or create_plan_id(),
                original_query=plan.original_query,
                final_answer=f"å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}",
                step_results=list(state.step_results.values()),
                overall_confidence=0.0,
                overall_status="failed",
                replan_count=state.replan_count,
                total_execution_time_ms=state.get_execution_time_ms()
            )

    def execute_plan(self, plan: ExecutionPlan) -> ExecutionResult:
        """
        è¨ˆç”»ã‚’å®Ÿè¡Œï¼ˆGRACEãƒã‚¤ãƒ†ã‚£ãƒ–å®Ÿè£…ï¼‰
        Args:
            plan: å®Ÿè¡Œã™ã‚‹è¨ˆç”»
        Returns:
            ExecutionResult: å®Ÿè¡Œçµæœ
        """
        logger.info(f"Executing plan: {plan.plan_id}, steps={len(plan.steps)}")

        # å—ã‘å–ã£ãŸãƒ—ãƒ©ãƒ³å†…å®¹ã‚’ãƒ­ã‚°å‡ºåŠ›
        logger.info(f"Received Execution Plan in Executor (blocking):\n{plan.model_dump_json(indent=2)}")

        # å®Ÿè¡ŒçŠ¶æ…‹ã‚’åˆæœŸåŒ–
        state = ExecutionState(plan=plan)
        state.start_time = time.time()

        try:
            # å„ã‚¹ãƒ†ãƒƒãƒ—ã‚’é †æ¬¡å®Ÿè¡Œ
            for step in plan.steps:
                # ã‚­ãƒ£ãƒ³ã‚»ãƒ«ãƒã‚§ãƒƒã‚¯
                if state.is_cancelled:
                    logger.info("Execution cancelled")
                    break

                # ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯
                if not self._check_dependencies(step, state):
                    logger.warning(f"Step {step.step_id}: Dependencies not met, skipping")
                    state.step_statuses[step.step_id] = StepStatus.SKIPPED
                    continue

                # ã‚¹ãƒ†ãƒƒãƒ—é–‹å§‹ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
                state.step_statuses[step.step_id] = StepStatus.RUNNING
                if self.on_step_start:
                    self.on_step_start(step)

                # ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œ
                step_execution = self._execute_step(step, state)
                
                result = None
                if isinstance(step_execution, Generator):
                    # ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã®å ´åˆã¯æœ€å¾Œã¾ã§å›ã—ã¦æœ€çµ‚çµæœã‚’å–å¾—
                    try:
                        while True:
                            # ä¸­é–“ã‚¤ãƒ™ãƒ³ãƒˆï¼ˆãƒ­ã‚°ãªã©ï¼‰ã¯ãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ç‰ˆã§ã¯ç„¡è¦–ã™ã‚‹ã‹ãƒ­ã‚°å‡ºåŠ›
                            event = next(step_execution)
                            if isinstance(event, dict) and event.get("type") == "log":
                                logger.info(event.get("content"))
                    except StopIteration as e:
                        result = e.value
                else:
                    result = step_execution

                # çµæœã‚’ä¿å­˜
                state.step_results[step.step_id] = result
                state.step_statuses[step.step_id] = (
                    StepStatus.SUCCESS if result.status == "success" else StepStatus.FAILED
                )

                # ã‚¹ãƒ†ãƒƒãƒ—å®Œäº†ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
                if self.on_step_complete:
                    self.on_step_complete(result)

                # ask_user ã®å ´åˆã€ä»‹å…¥ãŒå¿…è¦
                if step.action == "ask_user" and result.status == "success":
                    if self.on_intervention_required and isinstance(result.output, str):
                        try:
                            output_data = eval(result.output) if result.output.startswith("{}") else {"question": result.output}
                        except Exception:
                            output_data = {"question": result.output}

                        user_response = self.on_intervention_required("ask_user", output_data)
                        if user_response:
                            # ãƒ¦ãƒ¼ã‚¶ãƒ¼å¿œç­”ã‚’æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã§åˆ©ç”¨å¯èƒ½ã«ã™ã‚‹
                            result.output = f"ãƒ¦ãƒ¼ã‚¶ãƒ¼å¿œç­”: {user_response}"
                            state.step_results[step.step_id] = result

                # å¤±æ•—æ™‚ã®ãƒªãƒ—ãƒ©ãƒ³ï¼ˆPhase 4ã§æœ‰åŠ¹åŒ–ï¼‰
                if result.status == "failed" and self.replan_orchestrator:
                    replan_result = self.replan_orchestrator.handle_step_failure(
                        step_result=result,
                        current_plan=plan,
                        completed_results=state.step_results,
                        replan_count=state.replan_count
                    )
                    if replan_result and replan_result.success and replan_result.new_plan:
                        logger.info(f"Replanning: {replan_result.reason}")
                        state.replan_count += 1
                        # æ–°ã—ã„è¨ˆç”»ã§å†å®Ÿè¡Œï¼ˆå†å¸°ï¼‰
                        return self.execute_plan(replan_result.new_plan)

            # å…¨ä½“ã®ä¿¡é ¼åº¦ã‚’è¨ˆç®—
            state.overall_confidence = self._calculate_overall_confidence(state)
            state.end_time = time.time()

            # å®Ÿè¡Œçµæœã‚’ç”Ÿæˆ
            return self._create_execution_result(state)

        except Exception as e:
            logger.error(f"Execution failed: {e}", exc_info=True)
            state.end_time = time.time()

            return ExecutionResult(
                plan_id=plan.plan_id or create_plan_id(),
                original_query=plan.original_query,
                final_answer=f"å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}",
                step_results=list(state.step_results.values()),
                overall_confidence=0.0,
                overall_status="failed",
                replan_count=state.replan_count,
                total_execution_time_ms=state.get_execution_time_ms()
            )

    def _check_dependencies(self, step: PlanStep, state: ExecutionState) -> bool:
        """ä¾å­˜ã‚¹ãƒ†ãƒƒãƒ—ã®å®Œäº†ç¢ºèª"""
        for dep_id in step.depends_on:
            if dep_id not in state.step_results:
                return False
            if state.step_results[dep_id].status == "failed":
                return False
        return True

    def _execute_step(self, step: PlanStep, state: ExecutionState) -> Any:
        """
        å€‹åˆ¥ã‚¹ãƒ†ãƒƒãƒ—ã®å®Ÿè¡Œ
        Args:
            step: å®Ÿè¡Œã™ã‚‹ã‚¹ãƒ†ãƒƒãƒ—
            state: ç¾åœ¨ã®å®Ÿè¡ŒçŠ¶æ…‹
        Returns:
            StepResult or Generator: ã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œçµæœï¼ˆã¾ãŸã¯ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ï¼‰
        """
        logger.info(f"Executing step {step.step_id}: {step.action} - {step.description}")

        start_time = time.time()

        try:
            # ãƒ„ãƒ¼ãƒ«ã‚’å–å¾—
            tool = self.tool_registry.get(step.action)
            
            # --- äº’æ›æ€§ç¶­æŒã®ãŸã‚ã®ç‰¹åˆ¥ãªãƒãƒ³ãƒ‰ãƒªãƒ³ã‚° ---
            if tool is None and step.action == "run_legacy_agent":
                # ãƒ„ãƒ¼ãƒ«ã¨ã—ã¦ç™»éŒ²ã•ã‚Œã¦ã„ãªã„ãŒã€ä»¥å‰ã®Legacyãƒ—ãƒ©ãƒ³ãŒæ®‹ã£ã¦ã„ã‚‹å ´åˆ
                return self._execute_legacy_agent_step(step, state, start_time)
            
            if tool is None:
                raise ValueError(f"Unknown action: {step.action}")

            # ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œå¼•æ•°ã‚’æº–å‚™
            kwargs = self._prepare_tool_kwargs(step, state)

            # å®Ÿè¡Œ
            tool_result: ToolResult = tool.execute(**kwargs)

            # --- UIã¸ã®ä¸­é–“çµæœé€šçŸ¥ (æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹è¡¨ç¤ºç”¨) ---
            if tool_result.success and tool_result.output:
                import json
                try:
                    # RAGæ¤œç´¢çµæœãªã©ã¯ãƒªã‚¹ãƒˆ/è¾æ›¸ãªã®ã§æ•´å½¢ã™ã‚‹
                    out_display = json.dumps(tool_result.output, indent=2, ensure_ascii=False) if isinstance(tool_result.output, (list, dict)) else str(tool_result.output)
                except Exception:
                    out_display = str(tool_result.output)
                
                # IPOé¢¨ã®ãƒ©ãƒ™ãƒ«ã‚’ã¤ã‘ã¦é€šçŸ¥
                yield {
                    "type": "log",
                    "content": f"ğŸ“ ã€ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œçµæœ: {step.action}ã€‘\n{out_display}"
                }

            # å®Ÿè¡Œæ™‚é–“
            execution_time = int((time.time() - start_time) * 1000)

            # ----------------------
            # ä¿¡é ¼åº¦ã‚’è¨ˆç®—ï¼ˆstateå¼•æ•°ã‚’æ¸¡ã™ï¼‰
            # ----------------------
            # confidence = self._calculate_step_confidence(tool_result, step, state)
            confidence = self._llm_calculate_step_confidence(tool_result, step, state)

            # ã‚½ãƒ¼ã‚¹ã‚’æŠ½å‡º
            sources = self._extract_sources(tool_result)

            return StepResult(
                step_id=step.step_id,
                status="success" if tool_result.success else "failed",
                output=self._format_output(tool_result.output),
                confidence=confidence,
                sources=sources,
                error=tool_result.error if not tool_result.success else None,
                execution_time_ms=execution_time
            )

        except Exception as e:
            logger.error(f"Step {step.step_id} failed: {e}")
            execution_time = int((time.time() - start_time) * 1000)

            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
            if step.fallback:
                logger.info(f"Attempting fallback: {step.fallback}")
                fallback_result = self._execute_fallback(step, state)
                if fallback_result.status == "success":
                    return fallback_result

            return StepResult(
                step_id=step.step_id,
                status="failed",
                output=None,
                confidence=0.0,
                error=str(e),
                execution_time_ms=execution_time
            )

    def _execute_legacy_agent_step(self, step: PlanStep, state: ExecutionState, start_time: float) -> Generator[Any, None, StepResult]:
        """Legacy ReActAgent ã‚’ä½¿ç”¨ã—ãŸã‚¹ãƒ†ãƒƒãƒ—å®Ÿè¡Œï¼ˆã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ç‰ˆï¼‰"""
        if not LEGACY_AGENT_AVAILABLE:
            raise ImportError("agent_service module not found")

        # 1. ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æº–å‚™
        available_collections = get_available_collections_from_qdrant_helper()
        if not available_collections:
             available_collections = self.config.qdrant.search_priority

        # 2. AgentåˆæœŸåŒ–
        agent = ReActAgent(
            selected_collections=available_collections,
            model_name=self.config.llm.model
        )

        query = step.query or step.description
        logger.info(f"Running Legacy Agent with query: {query}")

        final_answer = ""
        sources = []
        
        # 3. ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆå®Ÿè¡Œï¼ˆã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ï¼‰
        # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ã‚¤ãƒ™ãƒ³ãƒˆã‚’æ‹¾ã„ãªãŒã‚‰ã€ãƒ„ãƒ¼ãƒ«çµæœã‹ã‚‰ã‚½ãƒ¼ã‚¹ã‚’åé›†
        for event in agent.execute_turn(query):
            # ã‚¤ãƒ™ãƒ³ãƒˆã‚’ãã®ã¾ã¾ä¸Šä½ã¸æµã™ï¼ˆUIè¡¨ç¤ºç”¨ï¼‰
            yield event

            # ãƒ­ã‚°å‡ºåŠ›ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
            if event["type"] == "log":
                logger.info(f"[LegacyAgent] {event['content']}")
            elif event["type"] == "tool_call":
                logger.info(f"[LegacyAgent] Tool Call: {event['name']} args={event['args']}")
            elif event["type"] == "tool_result":
                logger.info(f"[LegacyAgent] Tool Result (len={len(event['content'])})")
                # ã‚½ãƒ¼ã‚¹æŠ½å‡º (ç°¡æ˜“çš„ãªæ–‡å­—åˆ—è§£æ)
                if "Source:" in event["content"]:
                     import re
                     # Source: filename.csv ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æŠ½å‡º
                     found_sources = re.findall(r"Source:\s*([a-zA-Z0-9_.\-]+)", event["content"])
                     if found_sources:
                         sources.extend(found_sources)
            elif event["type"] == "final_answer":
                final_answer = event["content"]
        
        # 4. çµæœæ§‹ç¯‰
        execution_time = int((time.time() - start_time) * 1000)
        
        # ã‚½ãƒ¼ã‚¹ã®é‡è¤‡æ’é™¤
        sources = list(set(sources))
        
        # Confidenceè¨ˆç®— (ç°¡æ˜“ç‰ˆ)
        confidence = 0.8 if final_answer and "ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“" not in final_answer else 0.3
        
        # ConfidenceScoreã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ä½œæˆã—ã¦ä¿å­˜
        conf_score_obj = ConfidenceScore(
             score=confidence,
             factors=ConfidenceFactors(
                 source_count=len(sources),
                 search_result_count=len(sources), 
                 llm_self_confidence=confidence
             )
        )
        self.step_confidence_scores[step.step_id] = conf_score_obj
        
        # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³åˆ¤å®š
        if self.on_confidence_update:
             action = self.confidence_calculator.decide_action(conf_score_obj)
             self.on_confidence_update(conf_score_obj, action)

        return StepResult(
            step_id=step.step_id,
            status="success",
            output=final_answer,
            confidence=confidence,
            sources=sources,
            error=None,
            execution_time_ms=execution_time
        )

    def _prepare_tool_kwargs(
        self,
        step: PlanStep,
        state: ExecutionState
    ) -> Dict[str, Any]:
        """ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œå¼•æ•°ã‚’æº–å‚™"""
        kwargs = {
            "query": step.query or step.description,
        }

        if step.action == "rag_search":
            kwargs["collection"] = step.collection

        elif step.action == "reasoning":
            # ä¾å­˜ã‚¹ãƒ†ãƒƒãƒ—ã®çµæœã‚’ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦è¿½åŠ 
            context_parts = []
            sources = []
            logger.info(f"--- Step3 [DEBUG] Reasoning Step ---")
            logger.info(f"Step: {step}")
            logger.info(f"State: {state}")

            for dep_id in step.depends_on:
                if dep_id in state.step_results:
                    dep_result = state.step_results[dep_id]
                    dep_output = dep_result.output

                    if dep_output:
                        # æ–‡å­—åˆ—åŒ–ã•ã‚ŒãŸãƒªã‚¹ãƒˆã‚’å¾©å…ƒã™ã‚‹è©¦ã¿
                        if isinstance(dep_output, str):
                            try:
                                # RAGæ¤œç´¢çµæœã¯ "[{...}, {...}]" å½¢å¼ã§æ–‡å­—åˆ—åŒ–ã•ã‚Œã¦ã„ã‚‹
                                if dep_output.startswith("[{") or dep_output.startswith("[{'"):
                                    import ast
                                    parsed = ast.literal_eval(dep_output)
                                    if isinstance(parsed, list):
                                        sources.extend(parsed)
                                        continue
                            except (ValueError, SyntaxError):
                                pass
                            # ãƒ‘ãƒ¼ã‚¹ã§ããªã„å ´åˆã¯ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨ã—ã¦è¿½åŠ 
                            context_parts.append(f"--- å‚ç…§æƒ…å ± (Step {dep_id}) ---\n{dep_output}")
                        elif isinstance(dep_output, list):
                            sources.extend(dep_output)

            if sources:
                kwargs["sources"] = sources
            if context_parts:
                kwargs["context"] = "\n\n".join(context_parts)

        elif step.action == "ask_user":
            kwargs.update({
                "question": step.query or step.description,
                "reason": f"ã‚¹ãƒ†ãƒƒãƒ— {step.step_id}: {step.description}",
                "urgency": "blocking"
            })

        return kwargs

    def _execute_fallback(
        self,
        step: PlanStep,
        state: ExecutionState
    ) -> StepResult:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ"""
        fallback_step = PlanStep(
            step_id=step.step_id,
            action=step.fallback,
            description=f"[Fallback] {step.description}",
            query=step.query,
            depends_on=step.depends_on,
            expected_output=step.expected_output,
            fallback=None  # äºŒé‡ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¯ç„¡ã—
        )
        step_execution = self._execute_step(fallback_step, state)
        if isinstance(step_execution, Generator):
            try:
                while True:
                    next(step_execution)
            except StopIteration as e:
                return e.value
        return step_execution

    def _llm_calculate_step_confidence(
        self,
        tool_result: ToolResult,
        step: PlanStep,
        state: ExecutionState
        ) ->float:
        """
        LLMã‚’ä½¿ç”¨ã—ãŸã‚¹ãƒ†ãƒƒãƒ—ä¿¡é ¼åº¦ã®è¨ˆç®—
        """
        if not tool_result.success:
            return 0.0

        factors = tool_result.confidence_factors
        logger.info(f"[_llm_calculate_step_confidence] Initial factors: {factors}")

        # ConfidenceFactorsã‚’æ§‹ç¯‰
        # source_countã®æ±ºå®š: ãƒ„ãƒ¼ãƒ«ãŒæ˜ç¤ºçš„ã«è¿”ã—ãŸå€¤ã‚’å„ªå…ˆ
        extracted_sources = self._extract_sources(tool_result)
        source_count = factors.get("source_count", len(extracted_sources))

        # ã‚½ãƒ¼ã‚¹ä¸€è‡´åº¦ (Source Agreement) ã®è¨ˆç®—
        source_agreement = 1.0
        if source_count > 1:
            # ãƒ„ãƒ¼ãƒ«çµæœã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
            texts = []
            if isinstance(tool_result.output, list):
                for item in tool_result.output:
                    if isinstance(item, dict):
                        payload = item.get("payload", {})
                        # content, text, answer ãªã©ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’æ¢ã™
                        content = payload.get("content") or payload.get("text") or payload.get("answer")
                        if content:
                            texts.append(str(content))
            
            if len(texts) > 1:
                try:
                    sa_calc = create_source_agreement_calculator(config=self.config)
                    source_agreement = sa_calc.calculate(texts)
                    logger.info(f"[_llm_calculate_step_confidence] Calculated source_agreement: {source_agreement:.4f}")
                except Exception as e:
                    logger.warning(f"Failed to calculate source_agreement: {e}")
                    source_agreement = 0.5

        # ä¾å­˜ã‚¹ãƒ†ãƒƒãƒ—ã‹ã‚‰ã®ã‚¹ã‚³ã‚¢ç¶™æ‰¿ãƒ­ã‚¸ãƒƒã‚¯
        current_result_count = factors.get("result_count", 0)
        current_max_score = factors.get("max_score", factors.get("avg_score", 0.0))
        current_avg_score = factors.get("avg_score", 0.0)

        # è‡ªèº«ã§æ¤œç´¢ã—ã¦ãŠã‚‰ãšã€ã‹ã¤æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—ãªã©ã®å ´åˆã€ä¾å­˜å…ƒã®ã‚¹ã‚³ã‚¢ã‚’å¼•ãç¶™ã
        if current_result_count == 0 and not (step.action in ["rag_search", "web_search"]):
            inherited_max = 0.0
            inherited_found = False
            for dep_id in step.depends_on:
                if dep_id in state.step_results:
                    dep_res = state.step_results[dep_id]
                    # ä¾å­˜å…ˆã®ä¿¡é ¼åº¦ã‚’ç¶™æ‰¿
                    if dep_res.confidence > inherited_max:
                        inherited_max = dep_res.confidence
                        inherited_found = True

            if inherited_found:
                logger.info(f"[_llm_calculate_step_confidence] Inherited scores from dependency: max={inherited_max}")
                current_max_score = inherited_max
                current_avg_score = inherited_max
                current_result_count = 1  # ä»®æƒ³çš„ã«1ä»¶ã‚ã£ãŸã¨ã¿ãªã™

        confidence_factors = ConfidenceFactors(
            # RAGæ¤œç´¢é–¢é€£
            search_result_count=current_result_count,
            search_avg_score=current_avg_score,
            search_max_score=current_max_score,
            search_score_variance=factors.get("score_variance", 1.0),
            # ã‚½ãƒ¼ã‚¹é–¢é€£
            source_count=source_count,
            source_agreement=source_agreement,
            # ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œé–¢é€£
            tool_success_rate=1.0 if tool_result.success else 0.0,
            tool_execution_count=1,
            tool_success_count=1 if tool_result.success else 0,
            # ã‚¹ãƒ†ãƒƒãƒ—ã‚¿ã‚¤ãƒ—
            is_search_step=(step.action in ["rag_search", "web_search"])
        )
        logger.info(f"[_llm_calculate_step_confidence] Constructed ConfidenceFactors: {confidence_factors}")

        # ConfidenceCalculatorã§è¨ˆç®—
        confidence_score = self.confidence_calculator.llm_calculate(
            factors=confidence_factors,
            step_description=step.description,
            tool_output=str(tool_result.output)
        )

        # ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã®ConfidenceScoreã‚’ä¿å­˜
        self.step_confidence_scores[step.step_id] = confidence_score

        # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ±ºå®šã‚’å–å¾—
        action_decision = self.confidence_calculator.decide_action(confidence_score)

        # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§é€šçŸ¥ï¼ˆPhase 3ã®HITLã¨é€£æºï¼‰
        if self.on_confidence_update:
            self.on_confidence_update(confidence_score, action_decision)

        logger.info(
            f"Step {step.step_id} confidence: {confidence_score.score:.2f} "
            f"(level={confidence_score.level}, action={action_decision.level.value})"
        )

        return confidence_score.score

    # -------------------
    # Step 3ã®è©•ä¾¡ã‚’æ‹…å½“ã™ã‚‹é–¢æ•°
    # -------------------
    def _calculate_step_confidence(
        self,
        tool_result: ToolResult,
        step: PlanStep,
        state: ExecutionState
    ) -> float:
        """
        ã‚¹ãƒ†ãƒƒãƒ—ã®ä¿¡é ¼åº¦ã‚’è¨ˆç®—ï¼ˆConfidenceCalculatorä½¿ç”¨ - Heuristicç‰ˆï¼‰
        Args:
            tool_result: ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œçµæœ
            step: å®Ÿè¡Œã—ãŸã‚¹ãƒ†ãƒƒãƒ—
            state: ç¾åœ¨ã®å®Ÿè¡ŒçŠ¶æ…‹
        Returns:
            float: ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ (0.0-1.0)
        """
        if not tool_result.success:
            return 0.0

        factors = tool_result.confidence_factors
        logger.info(f"[_calculate_step_confidence] Initial factors: {factors}")

        # ConfidenceFactorsã‚’æ§‹ç¯‰
        # source_countã®æ±ºå®š: ãƒ„ãƒ¼ãƒ«ãŒæ˜ç¤ºçš„ã«è¿”ã—ãŸå€¤ã‚’å„ªå…ˆ
        extracted_sources = self._extract_sources(tool_result)
        source_count = factors.get("source_count", len(extracted_sources))

        # ã‚½ãƒ¼ã‚¹ä¸€è‡´åº¦ (Source Agreement) ã®è¨ˆç®—
        source_agreement = 1.0
        if source_count > 1:
            # ãƒ„ãƒ¼ãƒ«çµæœã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
            texts = []
            if isinstance(tool_result.output, list):
                for item in tool_result.output:
                    if isinstance(item, dict):
                        payload = item.get("payload", {})
                        content = payload.get("content") or payload.get("text") or payload.get("answer")
                        if content:
                            texts.append(str(content))
            
            if len(texts) > 1:
                try:
                    sa_calc = create_source_agreement_calculator(config=self.config)
                    source_agreement = sa_calc.calculate(texts)
                    logger.info(f"[_calculate_step_confidence] Calculated source_agreement: {source_agreement:.4f}")
                except Exception as e:
                    logger.warning(f"Failed to calculate source_agreement: {e}")
                    source_agreement = 0.5

        # ä¾å­˜ã‚¹ãƒ†ãƒƒãƒ—ã‹ã‚‰ã®ã‚¹ã‚³ã‚¢ç¶™æ‰¿ãƒ­ã‚¸ãƒƒã‚¯
        current_result_count = factors.get("result_count", 0)
        current_max_score = factors.get("max_score", factors.get("avg_score", 0.0))
        current_avg_score = factors.get("avg_score", 0.0)

        # è‡ªèº«ã§æ¤œç´¢ã—ã¦ãŠã‚‰ãšã€ã‹ã¤æ¨è«–ã‚¹ãƒ†ãƒƒãƒ—ãªã©ã®å ´åˆã€ä¾å­˜å…ƒã®ã‚¹ã‚³ã‚¢ã‚’å¼•ãç¶™ã
        if current_result_count == 0 and not (step.action in ["rag_search", "web_search"]):
            inherited_max = 0.0
            inherited_found = False
            for dep_id in step.depends_on:
                if dep_id in state.step_results:
                    dep_res = state.step_results[dep_id]
                    # ä¾å­˜å…ˆã®ä¿¡é ¼åº¦ã‚’ç¶™æ‰¿
                    if dep_res.confidence > inherited_max:
                        inherited_max = dep_res.confidence
                        inherited_found = True
            
            if inherited_found:
                logger.info(f"[_calculate_step_confidence] Inherited scores from dependency: max={inherited_max}")
                current_max_score = inherited_max
                current_avg_score = inherited_max
                current_result_count = 1  # ä»®æƒ³çš„ã«1ä»¶ã‚ã£ãŸã¨ã¿ãªã™

        confidence_factors = ConfidenceFactors(
            # RAGæ¤œç´¢é–¢é€£
            search_result_count=current_result_count,
            search_avg_score=current_avg_score,
            search_max_score=current_max_score,
            search_score_variance=factors.get("score_variance", 1.0),
            # ã‚½ãƒ¼ã‚¹é–¢é€£
            source_count=source_count,
            source_agreement=source_agreement,
            # ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œé–¢é€£
            tool_success_rate=1.0 if tool_result.success else 0.0,
            tool_execution_count=1,
            tool_success_count=1 if tool_result.success else 0,
            # ã‚¹ãƒ†ãƒƒãƒ—ã‚¿ã‚¤ãƒ—
            is_search_step=(step.action in ["rag_search", "web_search"])
        )
        logger.info(f"[_calculate_step_confidence] Constructed ConfidenceFactors: {confidence_factors}")

        # ConfidenceCalculatorã§è¨ˆç®—
        confidence_score = self.confidence_calculator.calculate(confidence_factors)

        # ã‚¹ãƒ†ãƒƒãƒ—ã”ã¨ã®ConfidenceScoreã‚’ä¿å­˜
        self.step_confidence_scores[step.step_id] = confidence_score

        # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ±ºå®šã‚’å–å¾—
        action_decision = self.confidence_calculator.decide_action(confidence_score)

        # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§é€šçŸ¥ï¼ˆPhase 3ã®HITLã¨é€£æºï¼‰
        if self.on_confidence_update:
            self.on_confidence_update(confidence_score, action_decision)

        logger.info(
            f"Step {step.step_id} confidence: {confidence_score.score:.2f} "
            f"(level={confidence_score.level}, action={action_decision.level.value})"
        )

        return confidence_score.score

    def _extract_sources(self, tool_result: ToolResult) -> List[str]:
        """ãƒ„ãƒ¼ãƒ«çµæœã‹ã‚‰ã‚½ãƒ¼ã‚¹ã‚’æŠ½å‡º"""
        sources = []

        if isinstance(tool_result.output, list):
            for item in tool_result.output:
                if isinstance(item, dict):
                    payload = item.get("payload", {})
                    source = payload.get("source", "")
                    if source and source not in sources:
                        sources.append(source)

        return sources

    def _format_output(self, output: Any) -> Optional[str]:
        """å‡ºåŠ›ã‚’æ–‡å­—åˆ—ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        if output is None:
            return None
        if isinstance(output, str):
            return output
        if isinstance(output, dict):
            return str(output)
        if isinstance(output, list):
            # RAGæ¤œç´¢çµæœã®å ´åˆ
            if output and isinstance(output[0], dict):
                return str(output)
            return "\n".join(str(item) for item in output)
        return str(output)

    def _calculate_overall_confidence(self, state: ExecutionState) -> float:
        """
        å…¨ä½“ã®ä¿¡é ¼åº¦ã‚’è¨ˆç®—ï¼ˆConfidenceAggregator + LLMSelfEvaluatorä½¿ç”¨ï¼‰

        Args:
            state: å®Ÿè¡ŒçŠ¶æ…‹

        Returns:
            float: å…¨ä½“ã®ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢ (0.0-1.0)
        """
        if not state.step_results:
            return 0.0

        # å„ã‚¹ãƒ†ãƒƒãƒ—ã®ConfidenceScoreã‚’åé›†
        step_scores = list(self.step_confidence_scores.values())
        
        # æœ€æ–°ã®breakdownã‚’å–å¾—ï¼ˆãƒ™ãƒ¼ã‚¹ã¨ã—ã¦ä½¿ç”¨ï¼‰
        current_breakdown = {}
        if step_scores:
            # æœ€å¾Œã®ã‚¹ãƒ†ãƒƒãƒ—ã®breakdownã‚’ã‚³ãƒ”ãƒ¼
            current_breakdown = step_scores[-1].breakdown.copy()

        # æœ€çµ‚å›ç­”ã‚’å–å¾—
        final_answer = None
        # ... (ä¸­ç•¥) ...

        # LLMSelfEvaluatorã§æœ€çµ‚å›ç­”ã‚’è©•ä¾¡ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        if final_answer:
            # 1. LLMè‡ªå·±è©•ä¾¡ (Accuracy/Style etc.)
            try:
                eval_result = self.llm_evaluator.evaluate(
                    query=state.plan.original_query,
                    answer=final_answer,
                    sources=state.get_completed_sources()
                )
                
                score_val = 0.0
                if hasattr(eval_result, 'score'):
                    score_val = eval_result.score
                elif isinstance(eval_result, (int, float)):
                    score_val = float(eval_result)
                
                # breakdownã‚’æ›´æ–°
                current_breakdown["llm_self_eval"] = score_val
                
                # æ›´æ–°ã•ã‚ŒãŸbreakdownã‚’æŒã¤ConfidenceScoreã‚’ä½œæˆ
                llm_score = ConfidenceScore(
                    score=score_val,
                    factors=ConfidenceFactors(llm_self_confidence=score_val),
                    breakdown=current_breakdown.copy() # å…¨è¦ç´ ã‚’å«ã‚€breakdown
                )
                step_scores.append(llm_score)
                logger.info(f"LLM self-evaluation: {score_val:.2f}")

            except Exception as e:
                logger.warning(f"LLM self-evaluation failed: {e}")

            # 2. ã‚¯ã‚¨ãƒªç¶²ç¾…åº¦è©•ä¾¡ (Query Coverage)
            try:
                coverage_score = self.query_coverage_calculator.calculate(
                    query=state.plan.original_query,
                    answer=final_answer
                )
                
                # breakdownã‚’æ›´æ–°
                current_breakdown["query_coverage"] = coverage_score
                
                coverage_obj = ConfidenceScore(
                    score=coverage_score,
                    factors=ConfidenceFactors(query_coverage=coverage_score),
                    breakdown=current_breakdown.copy() # å…¨è¦ç´ ã‚’å«ã‚€breakdown
                )
                step_scores.append(coverage_obj)
                logger.info(f"Query coverage evaluation: {coverage_score:.2f}")
                
                # UIã¸ã®åæ˜ ã®ãŸã‚ã«ã€æœ€å¾Œã®ä¿¡é ¼åº¦æ›´æ–°ã¨ã—ã¦é€šçŸ¥ã™ã‚‹
                if self.on_confidence_update:
                    decision = ActionDecision(
                        level=InterventionLevel.SILENT,
                        confidence_score=coverage_score,
                        reason="Final coverage evaluation completed"
                    )
                    self.on_confidence_update(coverage_obj, decision)
                    
            except Exception as e:
                logger.warning(f"Query coverage evaluation failed: {e}")

        # ConfidenceAggregatorã§çµ±åˆ
        if step_scores:
            aggregated_score = self.confidence_aggregator.aggregate(
                scores=step_scores,
                method="weighted"
            )
            logger.info(f"Aggregated confidence: {aggregated_score:.2f}")
            return aggregated_score

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: å˜ç´”å¹³å‡
        confidences = [r.confidence for r in state.step_results.values()]
        return sum(confidences) / len(confidences)

    def _create_execution_result(self, state: ExecutionState) -> ExecutionResult:
        """å®Ÿè¡Œçµæœã‚’ç”Ÿæˆ"""
        # å…¨ä½“ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’åˆ¤å®š
        statuses = [r.status for r in state.step_results.values()]

        if state.is_cancelled:
            overall_status = "cancelled"
        elif all(s == "success" for s in statuses):
            overall_status = "success"
        elif any(s == "success" for s in statuses):
            overall_status = "partial"
        else:
            overall_status = "failed"

        # æœ€çµ‚å›ç­”ã‚’å–å¾—ï¼ˆæœ€å¾Œã®reasoningã¾ãŸã¯legacy_agentã‚¹ãƒ†ãƒƒãƒ—ã®å‡ºåŠ›ï¼‰
        final_answer = None
        for step in reversed(state.plan.steps):
            if (step.action in ["reasoning", "run_legacy_agent"]) and step.step_id in state.step_results:
                result = state.step_results[step.step_id]
                if result.status == "success":
                    final_answer = result.output
                    break

        return ExecutionResult(
            plan_id=state.plan.plan_id or create_plan_id(),
            original_query=state.plan.original_query,
            final_answer=final_answer,
            step_results=list(state.step_results.values()),
            overall_confidence=state.overall_confidence,
            overall_status=overall_status,
            replan_count=state.replan_count,
            total_execution_time_ms=state.get_execution_time_ms()
        )

    def cancel(self, state: ExecutionState):
        """å®Ÿè¡Œã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«"""
        state.is_cancelled = True
        logger.info("Execution cancelled")

    def resume(self, state: ExecutionState):
        """å®Ÿè¡Œã‚’å†é–‹"""
        state.is_paused = False
        logger.info("Execution resumed")

    # =========================================================================
    # Intervention Handler ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼ˆPhase 3ï¼‰
    # =========================================================================

    def _handle_intervention_notify(self, message: str) -> None:
        """é€šçŸ¥ãƒ¬ãƒ™ãƒ«ã®ä»‹å…¥å‡¦ç†ï¼ˆãƒ­ã‚°å‡ºåŠ›ã®ã¿ï¼‰"""
        logger.info(f"[NOTIFY] {message}")
        # UIã¸ã®é€šçŸ¥ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        if self.on_intervention_required:
            self.on_intervention_required("notify", {"message": message})

    def _handle_intervention_confirm(
        self,
        request: InterventionRequest
    ) -> InterventionResponse:
        """ç¢ºèªãƒ¬ãƒ™ãƒ«ã®ä»‹å…¥å‡¦ç†"""
        logger.info(f"[CONFIRM] {request.message}")

        # on_intervention_requiredã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§UIã«ç¢ºèªã‚’è¦æ±‚
        if self.on_intervention_required:
            user_response = self.on_intervention_required("confirm", {
                "message": request.message,
                "reason": request.reason,
                "options": request.options,
                "confidence": request.confidence_score,
            })

            if user_response:
                # ãƒ¦ãƒ¼ã‚¶ãƒ¼å¿œç­”ã‚’è§£æ
                if user_response in ["ã¯ã„ã€ç¶šè¡Œ", "proceed", "yes"]:
                    return InterventionResponse(action=InterventionAction.PROCEED)
                elif user_response in ["è¨ˆç”»ã‚’ä¿®æ­£", "modify"]:
                    return InterventionResponse(action=InterventionAction.MODIFY)
                elif user_response in ["ã‚­ãƒ£ãƒ³ã‚»ãƒ«", "cancel", "no"]:
                    return InterventionResponse(action=InterventionAction.CANCEL)
                else:
                    # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã¨ã—ã¦æ‰±ã†
                    return InterventionResponse(
                        action=InterventionAction.INPUT,
                        user_input=str(user_response)
                    )

        # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ãŒãªã„å ´åˆã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ç¶šè¡Œ
        return InterventionResponse(action=InterventionAction.PROCEED)

    def _handle_intervention_escalate(
        self,
        request: InterventionRequest
    ) -> InterventionResponse:
        """ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¬ãƒ™ãƒ«ã®ä»‹å…¥å‡¦ç†"""
        logger.info(f"[ESCALATE] {request.message}")

        # on_intervention_requiredã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§UIã«ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’è¦æ±‚
        if self.on_intervention_required:
            user_response = self.on_intervention_required("escalate", {
                "message": request.message,
                "question": request.question,
                "reason": request.reason,
                "confidence": request.confidence_score,
            })

            if user_response:
                return InterventionResponse(
                    action=InterventionAction.INPUT,
                    user_input=str(user_response)
                )

        # ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ãŒãªã„å ´åˆã¯ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆæ‰±ã„
        return InterventionResponse(
            action=InterventionAction.PROCEED,
            timeout_reached=True
        )

    def _handle_intervention_if_needed(
        self,
        action_decision: ActionDecision,
        step: PlanStep,
        state: ExecutionState
    ) -> Optional[InterventionResponse]:
        """
        å¿…è¦ã«å¿œã˜ã¦ä»‹å…¥ã‚’å‡¦ç†

        Args:
            action_decision: ä¿¡é ¼åº¦ã«åŸºã¥ãã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ±ºå®š
            step: ç¾åœ¨ã®ã‚¹ãƒ†ãƒƒãƒ—
            state: å®Ÿè¡ŒçŠ¶æ…‹

        Returns:
            InterventionResponse: ä»‹å…¥ãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼ˆä»‹å…¥ãŒç™ºç”Ÿã—ãŸå ´åˆï¼‰ã€ã¾ãŸã¯None
        """
        # SILENT/NOTIFYã¯è‡ªå‹•ç¶šè¡Œ
        if action_decision.level in [InterventionLevel.SILENT, InterventionLevel.NOTIFY]:
            if action_decision.level == InterventionLevel.NOTIFY:
                self.intervention_handler.handle(action_decision, step, state.plan)
            return None

        # CONFIRM/ESCALATEã¯ãƒ¦ãƒ¼ã‚¶ãƒ¼ä»‹å…¥ãŒå¿…è¦
        response = self.intervention_handler.handle(action_decision, step, state.plan)

        # ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã®å ´åˆã¯å®Ÿè¡Œã‚’ä¸­æ­¢
        if response.action == InterventionAction.CANCEL:
            state.is_cancelled = True

        return response


# =============================================================================
# ãƒ•ã‚¡ã‚¯ãƒˆãƒªé–¢æ•°
# =============================================================================

def create_executor(
    config: Optional[GraceConfig] = None,
    tool_registry: Optional[ToolRegistry] = None,
    **kwargs
) -> Executor:
    """Executorã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ"""
    return Executor(
        config=config,
        tool_registry=tool_registry,
        **kwargs
    )


# =============================================================================
# ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
# =============================================================================

__all__ = [
    "ExecutionState",
    "Executor",
    "create_executor",
]