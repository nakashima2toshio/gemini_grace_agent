{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thought Extraction Logic Check\n",
    "\n",
    "This notebook verifies the extraction logic for the **ReAct Agent**'s \"Thought\" component used in `agent_rag.py` (specifically `ui/pages/agent_chat_page.py`).\n",
    "\n",
    "It simulates how the system parses the agent's \"Thought\" output from the user input (`prompt`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Defined System Instruction\n",
    "\n",
    "The agent is instructed to always output `Thought:` before answering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_INSTRUCTION_TEMPLATE = \"\"\"\n",
    "You are a \"Hybrid Knowledge Agent\".\n",
    "\n",
    "## ReAct Process\n",
    "You must cycle through **Thought**, **Action**, and **Observation**.\n",
    "\n",
    "### 1. Using Tools\n",
    "**Thought: [Why search is needed, which collection, query]**\n",
    "(Tool call follows)\n",
    "\n",
    "### 2. Final Answer\n",
    "**Thought: [Reasoning based on info]**\n",
    "**Answer: [Final answer to user]**\n",
    "\"\"\"\n",
    "\n",
    "print(\"System Instruction Loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Thought Extraction Implementation\n",
    "\n",
    "This function replicates the logic in `ui/pages/agent_chat_page.py`'s `run_agent_turn` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_thought_only(model_response_text: str) -> str:\n",
    "    lines = model_response_text.split('\\n')\n",
    "    thought_lines = []\n",
    "    recording = False\n",
    "    \n",
    "    for line in lines:\n",
    "        clean_line = line.strip()\n",
    "        \n",
    "        # Start condition\n",
    "        if clean_line.startswith(\"Thought:\") or clean_line.startswith(\"考え:\") or clean_line.startswith(\"**Thought:**\"):\n",
    "            recording = True\n",
    "        \n",
    "        # End condition\n",
    "        if recording:\n",
    "            if clean_line.startswith(\"Answer:\") or clean_line.startswith(\"**Answer:**\") or clean_line.startswith(\"Action:\"):\n",
    "                recording = False\n",
    "                continue\n",
    "            \n",
    "            thought_lines.append(line)\n",
    "            \n",
    "    # Join and return\n",
    "    return "\\n".join(thought_lines).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Simulation\n",
    "\n",
    "Testing the extraction with sample agent responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case A: Search Needed\n",
    "user_prompt_a = \"Tell me about company rules\"\n",
    "model_response_a = \"\"\"\n",
    "Thought: User is asking about company rules. I need to search the 'livedoor' collection.\n",
    "Query: 'company rules'\n",
    "\"\"\"\n",
    "\n",
    "# Case B: Final Answer\n",
    "user_prompt_b = \"Thanks\"\n",
    "model_response_b = \"\"\"\n",
    "Thought: User is saying thanks. No search needed.\n",
    "Answer: You are welcome!\n",
    "\"\"\"\n",
    "\n",
    "# Run Test\n",
    "test_cases = [\n",
    "    (user_prompt_a, model_response_a),\n",
    "    (user_prompt_b, model_response_b)\n",
    "]\n",
    "\n",
    "for i, (prompt, resp) in enumerate(test_cases, 1):\n",
    "    print(f\"--- Case {i} ---\")\n",
    "    print(f\"Prompt: {prompt}\")\n",
    "    extracted = extract_thought_only(resp)\n",
    "    print(f\"> Extracted Thought:\\n{extracted}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}