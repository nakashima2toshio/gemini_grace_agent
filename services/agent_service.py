import os
import google.generativeai as genai
from google.generativeai import ChatSession, GenerativeModel
from typing import Dict, List, Any, Optional, Union, Tuple, Generator
import logging
from qdrant_client import QdrantClient # Added QdrantClient import

# Configuration and Tools
from config import AgentConfig, GeminiConfig
from agent_tools import search_rag_knowledge_base, list_rag_collections, RAGToolError
from services.qdrant_service import get_all_collections
from services.log_service import log_unanswered_question

logger = logging.getLogger(__name__)

# -----------------------------------------------------------------------------
# Constants & Configuration (Moved from agent_chat_page.py)
# -----------------------------------------------------------------------------

SYSTEM_INSTRUCTION_TEMPLATE = """
ã‚ãªãŸã¯ã€ç¤¾å†…ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ã¨é€£æºã—ãŸã€Œãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ãƒ»ãƒŠãƒ¬ãƒƒã‚¸ãƒ»ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€ã§ã™ã€‚
ã‚ãªãŸã®å½¹å‰²ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«å¯¾ã—ã¦ã€ä¸€èˆ¬çš„ãªçŸ¥è­˜ã¨ã€æä¾›ã•ã‚ŒãŸãƒ„ãƒ¼ãƒ«ï¼ˆç¤¾å†…ãƒŠãƒ¬ãƒƒã‚¸æ¤œç´¢ï¼‰ã‚’é©åˆ‡ã«ä½¿ã„åˆ†ã‘ã¦å›ç­”ã™ã‚‹ã“ã¨ã§ã™ã€‚

## ReAct ãƒ—ãƒ­ã‚»ã‚¹ã¨å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ (å³å®ˆ)

ã‚ãªãŸã¯ **Thought (æ€è€ƒ)**ã€**Action (ãƒ„ãƒ¼ãƒ«å®Ÿè¡Œ)**ã€**Observation (çµæœè¦³å¯Ÿ)** ã®ã‚µã‚¤ã‚¯ãƒ«ã‚’å›ã—ã¦å›ç­”ã«åˆ°é”ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

### 1. ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆï¼ˆæ¤œç´¢ãŒå¿…è¦ãªå ´åˆï¼‰
å¿…ãšä»¥ä¸‹ã®å½¢å¼ã§æ€è€ƒã‚’å‡ºåŠ›ã—ã¦ã‹ã‚‰ã€ãƒ„ãƒ¼ãƒ«ã‚’å‘¼ã³å‡ºã—ã¦ãã ã•ã„ã€‚
**Thought: [ãªãœæ¤œç´¢ãŒå¿…è¦ã‹ã€ã©ã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’ã€ã©ã‚“ãªã‚¯ã‚¨ãƒªã§æ¤œç´¢ã™ã‚‹ã‹]**
(ã“ã®å¾Œã«ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ãŒè¡Œã‚ã‚Œã¾ã™)

### 2. æœ€çµ‚å›ç­”ã‚’è¡Œã†å ´åˆï¼ˆæ¤œç´¢ãŒå®Œäº†ã—ãŸã€ã¾ãŸã¯æ¤œç´¢ä¸è¦ãªå ´åˆï¼‰
å¿…ãšä»¥ä¸‹ã®å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
**Thought: [å¾—ã‚‰ã‚ŒãŸæƒ…å ±ã«åŸºã¥ã„ã¦ã©ã†å›ç­”ã™ã‚‹ã‹ã€ã¾ãŸã¯æ¤œç´¢çµæœãŒãªã‹ã£ãŸå ´åˆã®åˆ¤æ–­]**
**Answer: [ãƒ¦ãƒ¼ã‚¶ãƒ¼ã¸ã®æœ€çµ‚çš„ãªå›ç­”]**

---

## è¡Œå‹•æŒ‡é‡ (Router Guidelines)

1.  **å°‚é–€çŸ¥è­˜ã®æ¤œç´¢**:
    *   ä»¥ä¸‹ã®ã„ãšã‚Œã‹ã«è©²å½“ã™ã‚‹å ´åˆã¯ã€**å¿…ãš `search_rag_knowledge_base` ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚**
        *   ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå›ºæœ‰ã®ä»•æ§˜ã€è¨­å®šã€ã‚¨ãƒ©ãƒ¼ã€ç¤¾å†…è¦å®šã€Wikipediaã®çŸ¥è­˜ã«é–¢ã™ã‚‹è³ªå•ã€‚
        *   ç‰¹å®šã®æƒ…å ±æºï¼ˆä¾‹: "Wikipediaã«ã‚ˆã‚‹ã¨"ã€"ãƒ©ã‚¤ãƒ–ãƒ‰ã‚¢ãƒ‹ãƒ¥ãƒ¼ã‚¹ã§"ï¼‰ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹è³ªå•ã€‚
        *   **å†…å®¹ãŒä¸æ˜ç­ã§ã‚ã£ã¦ã‚‚ã€ç¤¾å†…ãƒŠãƒ¬ãƒƒã‚¸ã«é–¢é€£ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã¨åˆ¤æ–­ã•ã‚Œã‚‹è³ªå•ï¼ˆä¾‹ï¼šç‰¹å®šã®ã‚³ãƒ¼ãƒ‰åã€ã‚·ã‚¹ãƒ†ãƒ åã€ãƒ©ãƒ³ãƒ€ãƒ ã«è¦‹ãˆã‚‹æ–‡å­—åˆ—ãªã©ï¼‰ã€‚**
        *   **ãŸã ã—ã€ä¸€èˆ¬çš„ãªãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°è¨€èªã®æ–‡æ³•ã‚„ä½¿ã„æ–¹ã«é–¢ã™ã‚‹è³ªå•ã«ã¯ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ç”¨ã—ãªã„ã§ãã ã•ã„ã€‚**
    *   **ç¾åœ¨åˆ©ç”¨å¯èƒ½ãªã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã¯ä»¥ä¸‹ã®é€šã‚Šã§ã™:**
        {available_collections}

2.  **ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³é¸æŠã®ãƒ’ãƒ³ãƒˆ (è¨€èªã¨å†…å®¹ã®ãƒãƒƒãƒãƒ³ã‚°)**:
    *   è³ªå•ã®è¨€èªã¨å†…å®¹ã«å¿œã˜ã¦ã€æœ€é©ãªã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚
    *   **`cc_news`**: **è‹±èª (English)** ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã€‚ **è‹±èªã®è³ªå•ã«ã¯ã¾ãšã“ã‚Œã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚æ¤œç´¢ã‚¯ã‚¨ãƒªã‚‚è‹±èªã®ã¾ã¾ã«ã—ã¦ãã ã•ã„ã€‚**
    *   **`wikipedia_ja`**: æ—¥æœ¬èª (Japanese) ã®ç™¾ç§‘äº‹å…¸ã€‚ä¸€èˆ¬çš„ãªçŸ¥è­˜ã‚„å®šç¾©ã€‚
    *   **`livedoor`**: æ—¥æœ¬èª (Japanese) ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ»ãƒ–ãƒ­ã‚°ã€‚**æ—¥æœ¬ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ã€ã‚¨ãƒ³ã‚¿ãƒ¡ã€æ˜ ç”»ãªã©ã®è©±é¡Œã«ã¯ã¾ãšã“ã‚Œã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚**
    *   **`japanese_text`**: æ—¥æœ¬èª (Japanese) ã®Webãƒ†ã‚­ã‚¹ãƒˆã€‚**ä»–ã®æ—¥æœ¬èªã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã§çµæœãŒå‡ºãªã„å ´åˆã®äºˆå‚™ã¨ã—ã¦ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚**

3.  **å†è©¦è¡Œæˆ¦ç•¥ (Multi-turn Strategy)**:
    *   **Step 1 (åˆå›æ¤œç´¢):** è³ªå•å†…å®¹ã«æœ€ã‚‚é©ã—ãŸã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’é¸ã³ã¾ã™ã€‚(è‹±èªãªã‚‰ `cc_news`ã€æ—¥æœ¬ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ»ã‚¨ãƒ³ã‚¿ãƒ¡ãªã‚‰ `livedoor`ã€ä¸€èˆ¬çŸ¥è­˜ãªã‚‰ `wikipedia`)
    *   **Step 2 (çµæœã®è©•ä¾¡):** ã‚‚ã—æ¤œç´¢çµæœãŒ `[[NO_RAG_RESULT]]` (çµæœãªã—) ã ã£ãŸå ´åˆã€**ã™ãã«è«¦ã‚ãšã«ä»¥ä¸‹ã®æˆ¦ç•¥ã‚’ã¨ã£ã¦ãã ã•ã„ã€‚**
        *   **ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å¤‰æ›´:** åˆ¥ã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’è©¦ã—ã¦ãã ã•ã„ã€‚ä¾‹ãˆã° `livedoor` ã§è¦‹ã¤ã‹ã‚‰ãªã‘ã‚Œã° `wikipedia_ja` ã‚’ã€ãã‚Œã§ã‚‚ãªã‘ã‚Œã° `japanese_text` ã‚’æ¤œç´¢ã—ã¦ãã ã•ã„ã€‚
        *   **ã‚¯ã‚¨ãƒªå¤‰æ›´:** ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å°‘ã—åºƒã’ã‚‹ã€ã¾ãŸã¯åŒç¾©èªã«å¤‰ãˆã¦å†æ¤œç´¢ã™ã‚‹ã€‚è‹±èªã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã«ã¯è‹±èªã§ã€æ—¥æœ¬èªã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã«ã¯æ—¥æœ¬èªã§æ¤œç´¢ã™ã‚‹ã‚ˆã†æ³¨æ„ã—ã¦ãã ã•ã„ã€‚
    *   **Step 3 (è«¦ã‚):** è¤‡æ•°ã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’è©¦è¡Œã—ã¦ã‚‚æƒ…å ±ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã®ã¿ã€ã€Œæƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€ã¨å›ç­”ã—ã¦ãã ã•ã„ã€‚

4.  **ä¸€èˆ¬çš„ãªä¼šè©±**:
    *   æŒ¨æ‹¶ã€é›‘è«‡ã€å˜ç´”ãªè¨ˆç®—ãªã©ã€å°‚é–€çŸ¥è­˜ãŒä¸è¦ãªå ´åˆã¯ã€ãƒ„ãƒ¼ãƒ«ã‚’ä½¿ã‚ãšã« `Answer:` ã§ç›´æ¥å›ç­”ã—ã¦ãã ã•ã„ã€‚

5.  **æ­£ç›´ã•ã¨ä¸è¶³æƒ…å ±ã®å‡¦ç† (Critical)**:
    *   ãƒ„ãƒ¼ãƒ«æ¤œç´¢ã®çµæœã€æƒ…å ±ãŒå¾—ã‚‰ã‚Œãªã‹ã£ãŸå ´åˆã¯ã€**çµ¶å¯¾ã«**ã‚ãªãŸã®äº‹å‰å­¦ç¿’çŸ¥è­˜ã§æé€ ã—ã¦ã¯ã„ã‘ã¾ã›ã‚“ã€‚
    *   ã€Œæä¾›ã•ã‚ŒãŸç¤¾å†…ãƒŠãƒ¬ãƒƒã‚¸ã«ã¯é–¢é€£æƒ…å ±ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€ã¨æ­£ç›´ã«ä¼ãˆã¦ãã ã•ã„ã€‚

6.  **å›ç­”ã®ã‚¹ã‚¿ã‚¤ãƒ«**:
    *   ä¸å¯§ãªæ—¥æœ¬èªï¼ˆã§ã™ãƒ»ã¾ã™èª¿ï¼‰ã§å›ç­”ã—ã¦ãã ã•ã„ã€‚
    *   æ¤œç´¢çµæœã«åŸºã¥ãå›ç­”ã®å ´åˆã€ã€Œç¤¾å†…ãƒŠãƒ¬ãƒƒã‚¸ã«ã‚ˆã‚‹ã¨...ã€ã‚„ã€Œã‚½ãƒ¼ã‚¹ [ãƒ•ã‚¡ã‚¤ãƒ«å] ã«ã‚ˆã‚‹ã¨...ã€ã¨å‡ºå…¸ã‚’æ˜ç¤ºã—ã¦ãã ã•ã„ã€‚
"""

REFLECTION_INSTRUCTION = """
## Reflection (è‡ªå·±è©•ä¾¡ã¨ä¿®æ­£)

ã‚ãªãŸã¯ä¸Šè¨˜ã§ä½œæˆã—ãŸã€Œå›ç­”æ¡ˆã€ã‚’ã€ä»¥ä¸‹ã®åŸºæº–ã§å®¢è¦³çš„ã«è©•ä¾¡ã—ã€å¿…è¦ã§ã‚ã‚Œã°ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚

**ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ:**
1.  **æ­£ç¢ºæ€§:** æ¤œç´¢çµæœ(ã‚‚ã—ã‚ã‚Œã°)ã«åŸºã¥ã„ã¦ã„ã‚‹ã‹ï¼Ÿ æä¾›ã•ã‚ŒãŸæƒ…å ±æºã«å«ã¾ã‚Œãªã„æƒ…å ±ã‚’æé€ ã—ã¦ã„ãªã„ã‹ï¼Ÿ
2.  **å›ç­”ã®é©åˆ‡æ€§:** ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã«ç›´æ¥çš„ã‹ã¤æ˜ç¢ºã«ç­”ãˆã¦ã„ã‚‹ã‹ï¼Ÿ
3.  **ã‚¹ã‚¿ã‚¤ãƒ«:** è¦ªã—ã¿ã‚„ã™ãã€ä¸å¯§ãªæ—¥æœ¬èªï¼ˆã§ã™ãƒ»ã¾ã™èª¿ï¼‰ã‹ï¼Ÿ ç®‡æ¡æ›¸ããªã©ã‚’æ´»ç”¨ã—ã¦èª­ã¿ã‚„ã™ã„ã‹ï¼Ÿ

**æŒ‡ç¤º:**
*   ä¿®æ­£ãŒä¸è¦ãªå ´åˆã§ã‚‚ã€å¿…ãš **Final Answer** ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
*   ä¿®æ­£ãŒå¿…è¦ãªå ´åˆã¯ã€ä¿®æ­£å¾Œã®å›ç­”ã‚’ **Final Answer** ã¨ã—ã¦å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
*   æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹ã¯ `Thought:` ã§å§‹ã‚ã¦ãã ã•ã„ã€‚

**å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ:**
Thought: [è©•ä¾¡ã¨ä¿®æ­£ã®æ€è€ƒãƒ—ãƒ­ã‚»ã‚¹]
Final Answer: [æœ€çµ‚çš„ãªå›ç­”]
"""

TOOLS_MAP: Dict[str, Any] = {
    'search_rag_knowledge_base': search_rag_knowledge_base,
    'list_rag_collections': list_rag_collections
}

# -----------------------------------------------------------------------------
# ReActAgent Class
# -----------------------------------------------------------------------------

class ReActAgent:
    def __init__(self, selected_collections: List[str], model_name: str):
        self.selected_collections = selected_collections
        self.model_name = model_name
        self.chat_session = self._setup_session()
        self.thought_log: List[str] = [] # Initialize thought_log here

    def _setup_session(self) -> ChatSession:
        """Geminiã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        api_key = os.getenv("GEMINI_API_KEY") or os.getenv("GOOGLE_API_KEY")
        if not api_key:
            raise ValueError("API Key missing: GEMINI_API_KEY or GOOGLE_API_KEY not set.")
        
        genai.configure(api_key=api_key)
        
        tools_list = [search_rag_knowledge_base, list_rag_collections]
        
        collections_str = ", ".join(self.selected_collections) if self.selected_collections else "(ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“)"
        system_instruction = SYSTEM_INSTRUCTION_TEMPLATE.format(available_collections=collections_str)
        
        model = genai.GenerativeModel(
            model_name=self.model_name,
            tools=tools_list,
            system_instruction=system_instruction
        )
        
        chat = model.start_chat(enable_automatic_function_calling=False)
        return chat

    def execute_turn(self, user_input: str) -> Generator[Dict[str, Any], None, None]:
        """
        ReAct â†’ Reflection ã®é †ã«ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚¿ãƒ¼ãƒ³ã‚’å®Ÿè¡Œã—ã€
        é€²æ—çŠ¶æ³ã‚’ã‚¤ãƒ™ãƒ³ãƒˆã¨ã—ã¦yieldã™ã‚‹ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã€‚
        """
        self.thought_log = [] # Clear log for new turn
        
        # --- Phase 1: ReAct Loop ---
        yield {"type": "log", "content": "ğŸ¤– **ReAct Phase Start**"}
        draft_answer: Optional[str] = None
        for event in self._execute_react_loop(user_input):
            yield event
            if event["type"] == "final_text": # This event carries the draft answer from ReAct
                draft_answer = event["content"]
        
        # --- Phase 2: Reflection ---
        if draft_answer:
            yield {"type": "log", "content": "ğŸ”„ **Reflection Phase (æ¨æ•²)**"}
            final_answer_after_reflection = yield from self._execute_reflection_phase(draft_answer)
            draft_answer = final_answer_after_reflection # Update draft with reflected answer

        yield {"type": "final_answer", "content": self._format_final_answer(draft_answer)}

    def _execute_react_loop(self, user_input: str) -> Generator[Dict[str, Any], None, None]:
        """
        ReActãƒ«ãƒ¼ãƒ—ã‚’å®Ÿè¡Œã—ã€å„ã‚¹ãƒ†ãƒƒãƒ—ã®ã‚¤ãƒ™ãƒ³ãƒˆã‚’yieldã™ã‚‹ã€‚
        æœ€çµ‚çš„ãªãƒ‰ãƒ©ãƒ•ãƒˆå›ç­”ã‚’ 'final_text' ã‚¤ãƒ™ãƒ³ãƒˆã¨ã—ã¦yieldã™ã‚‹ã€‚
        """
        current_response_obj = self.chat_session.send_message(user_input)
        max_turns = 10
        turn_count = 0
        final_text_from_react = ""
        
        while turn_count < max_turns:
            turn_count += 1
            function_call_found = False
            current_turn_text_from_model = ""

            for part in current_response_obj.parts:
                if part.text:
                    text = part.text.strip()
                    if "Thought:" in text or "è€ƒãˆ:" in text:
                        self.thought_log.append(f"ğŸ§  **Thought:**\n{text}")
                        yield {"type": "log", "content": f"ğŸ§  **Thought:**\n{text}"}
                        current_turn_text_from_model = text
                    else:
                        current_turn_text_from_model = text
                
                if part.function_call:
                    function_call_found = True
                    fn = part.function_call
                    tool_name = fn.name
                    tool_args = dict(fn.args)
                    
                    logger.info(f"Agent Tool Call: {tool_name}({tool_args})")
                    self.thought_log.append(f"ğŸ› ï¸ **Tool Call:** `{tool_name}`\nArgs: `{tool_args}`")
                    yield {"type": "tool_call", "name": tool_name, "args": tool_args}
                    
                    tool_result = ""
                    try:
                        if tool_name in TOOLS_MAP:
                            tool_result = TOOLS_MAP[tool_name](**tool_args) 
                        else:
                            tool_result = f"Error: Tool '{tool_name}' not found."
                    except RAGToolError as e:
                        tool_result = f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
                        logger.error(f"RAG Tool Error during '{tool_name}': {e}")
                    except Exception as e:
                        tool_result = f"äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼: {str(e)}"
                        logger.error(f"Unexpected error during tool '{tool_name}': {e}", exc_info=True)

                    log_tool_result = str(tool_result)[:500] + "..." if len(str(tool_result)) > 500 else str(tool_result)
                    self.thought_log.append(f"ğŸ“ **Tool Result:**\n{log_tool_result}")
                    yield {"type": "tool_result", "content": log_tool_result}
                    logger.info(f"Tool Result: {log_tool_result}")
                    
                    if isinstance(tool_result, str) and tool_result.startswith("[[NO_RAG_RESULT"):
                        reason = "NO_RESULT"
                        if "LOW_SCORE" in tool_result:
                            reason = "LOW_SCORE"
                        collection_arg = tool_args.get('collection_name', 'unknown')
                        log_unanswered_question(
                            query=user_input,
                            collections=[collection_arg],
                            reason=reason,
                            agent_response="(Search Failed)"
                        )

                    current_response_obj = self.chat_session.send_message(
                        [genai.protos.Part(
                            function_response={
                                "name": tool_name,
                                "response": {'result': tool_result}
                            }
                        )]
                    )
                    break 
            
            if not function_call_found:
                final_text_from_react = current_turn_text_from_model
                break
        
        yield {"type": "final_text", "content": final_text_from_react} # Yield the draft answer from ReAct

    def _execute_reflection_phase(self, draft_answer: str) -> Generator[Dict[str, Any], None, str]:
        """
        Reflectionãƒ•ã‚§ãƒ¼ã‚ºã‚’å®Ÿè¡Œã—ã€ä¿®æ­£å¾Œã®å›ç­”ã‚’è¿”ã™ã€‚
        é€²æ—çŠ¶æ³ã‚’ã‚¤ãƒ™ãƒ³ãƒˆã¨ã—ã¦yieldã™ã‚‹ã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ã€‚
        """
        final_response_text = draft_answer
        try:
            reflection_msg = f"{REFLECTION_INSTRUCTION}\n\n**ã‚ãªãŸã®å›ç­”æ¡ˆ:**\n{draft_answer}"
            reflection_response = self.chat_session.send_message(reflection_msg)
            
            reflection_text = reflection_response.text.strip()
            
            reflection_thought = ""
            reflection_answer = ""

            if "Final Answer:" in reflection_text:
                parts = reflection_text.split("Final Answer:", 1)
                reflection_thought = parts[0].strip()
                reflection_answer = parts[1].strip()
            else:
                reflection_thought = "Format mismatch in reflection."
                reflection_answer = reflection_text

            if reflection_thought:
                clean_thought = reflection_thought.replace("Thought:", "").strip()
                self.thought_log.append(f"ğŸ¤” **Reflection Thought:**\n{clean_thought}")
                logger.info(f"Reflection Thought: {clean_thought}")
                yield {"type": "log", "content": f"ğŸ¤” **Reflection Thought:**\n{clean_thought}"} # Yield reflection thought

            if reflection_answer:
                final_response_text = reflection_answer
                logger.info(f"Reflection Answer: {reflection_answer}")

        except Exception as e:
            logger.error(f"Error during reflection phase: {e}")
            self.thought_log.append(f"âš ï¸ **Reflection Error:** {str(e)}")
            yield {"type": "log", "content": f"âš ï¸ **Reflection Error:** {str(e)}"} # Yield reflection error
            final_response_text = draft_answer
        
        return final_response_text

    def _format_final_answer(self, raw_answer: str) -> str:
        """
        æœ€çµ‚å›ç­”ã®æ•´å½¢ã‚’è¡Œã†ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰ã€‚
        """
        if "Answer:" in raw_answer:
            parts = raw_answer.split("Answer:", 1)
            return parts[1].strip()
        elif raw_answer.startswith("Thought:"):
            return raw_answer.replace("Thought:", "").strip()
        elif raw_answer.startswith("è€ƒãˆ:"):
            return raw_answer.replace("è€ƒãˆ:", "").strip()
        return raw_answer

# Helper function (Moved from agent_chat_page.py)
def get_available_collections_from_qdrant_helper() -> List[str]:
    """Qdrantã‹ã‚‰åˆ©ç”¨å¯èƒ½ãªã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³åã‚’å–å¾— (helper for now, will integrate into Agent if needed)"""
    try:
        client = QdrantClient(url=os.getenv("QDRANT_URL", "http://localhost:6333"))
        collections = client.get_collections()
        return [c.name for c in collections.collections]
    except Exception as e:
        logger.error(f"Failed to fetch collections: {e}")
        return []
