#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
qdrant_search_page.py - Qdrantæ¤œç´¢ãƒšãƒ¼ã‚¸
========================================
Qdrantãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½¿ç”¨ã—ãŸæ„å‘³æ¤œç´¢

æ©Ÿèƒ½:
- ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æ¤œç´¢
- åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆ
- AIå¿œç­”ç”Ÿæˆ
"""

import warnings
import pandas as pd
import streamlit as st
from helper_llm import create_llm_client
from qdrant_client import QdrantClient

# ã‚µãƒ¼ãƒ“ã‚¹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from services.qdrant_service import (
    QdrantDataFetcher,
    embed_query_for_search,
    get_dynamic_collection_mapping,
    get_collection_embedding_params,
)
from services.file_service import load_source_qa_data
from qdrant_client_wrapper import search_collection, embed_sparse_query_unified # Import search_collection and embed_sparse_query_unified

def show_qdrant_search_page():
    """ç”»é¢5: Qdrantæ¤œç´¢"""
    st.title("ğŸ” Qdrantæ¤œç´¢")
    st.caption("Qdrantãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½¿ç”¨ã—ãŸæ„å‘³æ¤œç´¢")

    # Qdrantæ¥ç¶šç¢ºèª
    qdrant_url = "http://localhost:6333"
    client = None
    available_collections = []

    try:
        client = QdrantClient(url=qdrant_url)
        collections_response = client.get_collections()
        available_collections = [col.name for col in collections_response.collections]
    except Exception:
        st.error(f"âŒ Qdrantã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“: {qdrant_url}")
        st.warning("Qdrantã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
        st.code("python server.py", language="bash")
        st.caption("ã¾ãŸã¯")
        st.code("docker run -p 6333:6333 qdrant/qdrant", language="bash")
        return

    # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã¨CSVãƒ•ã‚¡ã‚¤ãƒ«ã®å¯¾å¿œè¡¨ã‚’è¡¨ç¤ºï¼ˆå‹•çš„å–å¾—ï¼‰
    st.subheader("ğŸ“Š ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã¨CSVãƒ•ã‚¡ã‚¤ãƒ«ã®å¯¾å¿œ")
    
    # å‹•çš„ãƒãƒƒãƒ”ãƒ³ã‚°ã®å–å¾—
    dynamic_mapping = get_dynamic_collection_mapping(client)
    
    if dynamic_mapping:
        mapping_data = []
        for collection, csv_file in dynamic_mapping.items():
            mapping_data.append(
                {
                    "ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å": collection,
                    "CSVãƒ•ã‚¡ã‚¤ãƒ«": csv_file,
                    "ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹": f"qa_output/{csv_file}",
                }
            )
        mapping_df = pd.DataFrame(mapping_data)
        st.table(mapping_df)
    else:
        st.info("ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã¨CSVãƒ•ã‚¡ã‚¤ãƒ«ã®å¯¾å¿œæƒ…å ±ã¯ã‚ã‚Šã¾ã›ã‚“ï¼ˆã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãŒå­˜åœ¨ã—ãªã„ã‹ã€å‘½åè¦å‰‡ãŒä¸€è‡´ã—ã¾ã›ã‚“ï¼‰")

    st.divider()

    if not available_collections:
        st.warning("åˆ©ç”¨å¯èƒ½ãªã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãŒã‚ã‚Šã¾ã›ã‚“")
        st.info("å…ˆã«ã€ŒQdrantç™»éŒ²ã€ã§ãƒ‡ãƒ¼ã‚¿ã‚’ç™»éŒ²ã—ã¦ãã ã•ã„")
        return

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šæ¤œç´¢è¨­å®š
    with st.sidebar:
        st.header("ğŸ”§ æ¤œç´¢è¨­å®š")

        # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³é¸æŠ
        collection = st.selectbox(
            "ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³",
            options=available_collections,
            help="æ¤œç´¢å¯¾è±¡ã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã‚’é¸æŠ",
        )

        # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æƒ…å ±è¡¨ç¤º
        if client and collection:
            col_info = get_collection_embedding_params(client, collection)
            st.info(f"ğŸ“Š {col_info['model']} ({col_info['dims']}æ¬¡å…ƒ)")

        # Top-Kè¨­å®š
        topk = st.slider(
            "æ¤œç´¢çµæœæ•°ï¼ˆTop-Kï¼‰", min_value=1, max_value=20, value=5, step=1
        )
        
        # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã®æœ‰åŠ¹åŒ–ãƒˆã‚°ãƒ«
        use_hybrid_search = st.checkbox("âš™ï¸ ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ã‚’æœ‰åŠ¹ã«ã™ã‚‹ (Sparse + Dense)", value=False)

        # ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰
        debug_mode = st.checkbox("ğŸ› ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰", value=False)

    # ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
    if "search_query" not in st.session_state:
        st.session_state.search_query = ""

    # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚»ã‚¯ã‚·ãƒ§ãƒ³
    with st.expander("ğŸ“‹ ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼", expanded=False):
        # QdrantDataFetcherã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆ
        try:
            client = QdrantClient(url=qdrant_url)
            data_fetcher = QdrantDataFetcher(client)

            # fetch_collection_source_infoã‚’ä½¿ç”¨ã—ã¦ã‚½ãƒ¼ã‚¹æƒ…å ±ã‚’å–å¾—
            source_info = data_fetcher.fetch_collection_source_info(collection)

            if "error" not in source_info:
                sources = source_info.get("sources", {})

                if sources:
                    st.caption(f"ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³: **{collection}**")

                    # å„ã‚½ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã«ã‚¨ã‚­ã‚¹ãƒ‘ãƒ³ãƒ€ãƒ¼ã‚’ä½œæˆ
                    for source, stats in sorted(sources.items()):
                        with st.expander(f"ğŸ“„ {source}", expanded=False):
                            st.markdown(
                                f"- æ¨å®šãƒ‡ãƒ¼ã‚¿æ•°: {stats['estimated_total']:,}ä»¶ ({stats['percentage']:.1f}%)"
                            )
                            st.markdown(f"- ç”Ÿæˆæ–¹æ³•: `{stats['method']}`")
                            st.markdown(f"- ãƒ‰ãƒ¡ã‚¤ãƒ³: `{stats['domain']}`")

                            # question, answerãƒ†ãƒ¼ãƒ–ãƒ«ã‚’è¡¨ç¤º
                            df_qa = load_source_qa_data(source, num_rows=20)
                            if df_qa is not None:
                                st.dataframe(
                                    df_qa, width='stretch', hide_index=True
                                )
                            else:
                                st.info(f"ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“: qa_output/{source}")
                else:
                    st.info("ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹æƒ…å ±ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            else:
                st.error(f"ã‚¨ãƒ©ãƒ¼: {source_info['error']}")
        except Exception as e:
            st.error(f"ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")

    st.divider()

    # æ¤œç´¢å…¥åŠ›
    st.subheader("ğŸ” æ¤œç´¢")
    query = st.text_input(
        "æ¤œç´¢ã‚¯ã‚¨ãƒªã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
        value=st.session_state.search_query,
        placeholder="æ¤œç´¢ã—ãŸã„è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
    )

    col_search, col_clear = st.columns([4, 1])
    with col_search:
        do_search = st.button("ğŸ” æ¤œç´¢å®Ÿè¡Œ", type="primary", width='stretch')
    with col_clear:
        if st.button("ğŸ—‘ï¸ ã‚¯ãƒªã‚¢", width='stretch'):
            st.session_state.search_query = ""
            st.rerun()

    # æ¤œç´¢å®Ÿè¡Œ
    if do_search and query.strip():
        try:
            client = QdrantClient(url=qdrant_url)

            # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ã«å¯¾å¿œã—ãŸåŸ‹ã‚è¾¼ã¿è¨­å®šã‚’å–å¾—
            collection_config = get_collection_embedding_params(client, collection)
            embedding_model = collection_config["model"]
            embedding_dims = collection_config.get("dims")

            if debug_mode:
                st.info(f"ğŸ” ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«: {embedding_model} ({embedding_dims}æ¬¡å…ƒ)")
                try:
                    # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³è¨­å®šã®ãƒ‡ãƒãƒƒã‚°è¡¨ç¤º
                    col_info_debug = client.get_collection(collection)
                    st.markdown("**ğŸ“‹ ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³è¨­å®š (Debug):**")
                    st.json(col_info_debug.model_dump() if hasattr(col_info_debug, 'model_dump') else col_info_debug.dict())
                except Exception as e:
                    st.error(f"ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³è¨­å®šã®å–å¾—ã«å¤±æ•—: {e}")

            # ã‚¯ã‚¨ãƒªã‚’åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã«å¤‰æ›
            with st.spinner("åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆä¸­..."):
                qvec = embed_query_for_search(query, embedding_model, embedding_dims)
                if debug_mode:
                    st.success(f"âœ… {len(qvec)}æ¬¡å…ƒã®ãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆã—ã¾ã—ãŸ")

            # Qdrantã§æ¤œç´¢
            with st.spinner("æ¤œç´¢ä¸­..."):
                sparse_vector = None
                if use_hybrid_search:
                    with st.spinner("Sparseãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆä¸­..."):
                        # sparse_vectorç”Ÿæˆ
                        sparse_vector = embed_sparse_query_unified(query)
                        if debug_mode:
                            st.success("âœ… Sparseãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
                
                # search_collectioné–¢æ•°ã‚’å‘¼ã³å‡ºã—
                hits_dict_list = search_collection( # search_collection returns List[Dict[str, Any]]
                    client=client,
                    collection_name=collection,
                    query_vector=qvec,
                    sparse_vector=sparse_vector if use_hybrid_search else None, # ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰æ¤œç´¢ãŒæœ‰åŠ¹ãªå ´åˆã®ã¿Sparseãƒ™ã‚¯ãƒˆãƒ«ã‚’æ¸¡ã™
                    limit=topk
                )
            
            # search_collectionã®æˆ»ã‚Šå€¤ã¯Dictã®ãƒªã‚¹ãƒˆãªã®ã§ã€Qdrantã®PointStructã«å¤‰æ› (UIè¡¨ç¤ºã®ãŸã‚)
            class MockHit: # æ—¢å­˜ã®UIè¡¨ç¤ºãƒ­ã‚¸ãƒƒã‚¯ã«åˆã‚ã›ã‚‹ãŸã‚
                def __init__(self, hit_dict):
                    self.score = hit_dict.get("score", 0.0)
                    self.id = hit_dict.get("id")
                    self.payload = hit_dict.get("payload")
            
            hits = [MockHit(h) for h in hits_dict_list]

            

            # æ¤œç´¢çµæœã‚’è¡¨ç¤º
            st.divider()
            st.subheader(f"ğŸ“Š æ¤œç´¢çµæœ (Top {len(hits)})")

            if not hits:
                st.warning("æ¤œç´¢çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                return

            # çµæœã‚’DataFrameã«å¤‰æ›
            rows = []
            for h in hits:
                row_data = {
                    "ã‚¹ã‚³ã‚¢": f"{h.score:.4f}",
                    "è³ªå•": h.payload.get("question", "N/A") if h.payload else "N/A",
                    "å›ç­”": h.payload.get("answer", "N/A") if h.payload else "N/A",
                    "ã‚½ãƒ¼ã‚¹": h.payload.get("source", "N/A") if h.payload else "N/A",
                }
                rows.append(row_data)

            df_results = pd.DataFrame(rows)
            st.dataframe(df_results, width='stretch', hide_index=True)

            # æœ€é«˜ã‚¹ã‚³ã‚¢ã®çµæœã‚’è©³ç´°è¡¨ç¤º
            if hits:
                best_hit = hits[0]
                st.divider()
                st.subheader("ğŸ† æœ€é«˜ã‚¹ã‚³ã‚¢ã®çµæœ")

                col1, col2 = st.columns([1, 3])
                with col1:
                    st.metric("ã‚¹ã‚³ã‚¢", f"{best_hit.score:.4f}")
                with col2:
                    if best_hit.payload:
                        source = best_hit.payload.get("source", "N/A")
                        st.caption(f"ã‚½ãƒ¼ã‚¹: {source}")

                if best_hit.payload:
                    question = best_hit.payload.get("question", "")
                    answer = best_hit.payload.get("answer", "")

                    st.markdown("**è³ªå•:**")
                    st.info(question)

                    st.markdown("**å›ç­”:**")
                    st.success(answer)

                    # Geminiã«ã‚ˆã‚‹æ—¥æœ¬èªå¿œç­”ç”Ÿæˆ
                    st.divider()
                    st.subheader("ğŸ§  AIå¿œç­”ï¼ˆGeminiï¼‰")

                    qa_prompt = (
                        "ä»¥ä¸‹ã®æ¤œç´¢çµæœã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•ã‚’è¸ã¾ãˆã¦ã€æ—¥æœ¬èªã§ç°¡æ½”ã‹ã¤æ­£ç¢ºã«å›ç­”ã—ã¦ãã ã•ã„ã€‚\n\n"
                        f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•:\n{query}\n\n"
                        f"æ¤œç´¢çµæœã®ã‚¹ã‚³ã‚¢: {best_hit.score:.4f}\n"
                        f"æ¤œç´¢çµæœã®è³ªå•: {question}\n"
                        f"æ¤œç´¢çµæœã®å›ç­”: {answer}\n"
                    )

                    with st.expander("ğŸ“ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè©³ç´°", expanded=False):
                        st.code(qa_prompt)

                    try:
                        with st.spinner("Gemini AIãŒå›ç­”ã‚’ç”Ÿæˆä¸­..."):
                            llm_client = create_llm_client(provider="gemini")
                            generated_answer = llm_client.generate_content(
                                prompt=qa_prompt,
                                model="gemini-2.0-flash"
                            )

                        if generated_answer and generated_answer.strip():
                            st.markdown("**AIå¿œç­”:**")
                            st.write(generated_answer)
                        else:
                            st.info("å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
                    except Exception as gen_err:
                        st.error(f"AIå¿œç­”ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {str(gen_err)}")
                        if debug_mode:
                            st.exception(gen_err)

        except Exception as e:
            st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            if debug_mode:
                st.exception(e)

            if "Connection refused" in str(e):
                st.warning("Qdrantã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„")
                st.code("python server.py", language="bash")
            elif "collection" in str(e).lower() and "not found" in str(e).lower():
                st.warning(f"ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ '{collection}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                st.info("ã€ŒQdrantç™»éŒ²ã€ã§ãƒ‡ãƒ¼ã‚¿ã‚’ç™»éŒ²ã—ã¦ãã ã•ã„")