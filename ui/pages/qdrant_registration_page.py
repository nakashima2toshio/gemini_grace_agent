#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
qdrant_registration_page.py - Qdrantç™»éŒ²ãƒšãƒ¼ã‚¸
==============================================
Q/Aãƒ‡ãƒ¼ã‚¿ã®Qdrantã¸ã®ç™»éŒ²æ©Ÿèƒ½

æ©Ÿèƒ½:
- CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰Qdrantã¸ã®ç™»éŒ²
- åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«ç”Ÿæˆ
"""

import logging
from datetime import datetime
from pathlib import Path
import re

import pandas as pd
import streamlit as st
from qdrant_client import QdrantClient

# ã‚µãƒ¼ãƒ“ã‚¹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‹ã‚‰ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from services.qdrant_service import (
    get_collection_stats,
    load_csv_for_qdrant,
    build_inputs_for_embedding,
    embed_texts_for_qdrant,
    create_or_recreate_collection_for_qdrant,
    build_points_for_qdrant,
    upsert_points_to_qdrant,
)
# Wrapperã‹ã‚‰ç›´æ¥ã‚¤ãƒ³ãƒãƒ¼ãƒˆ (Sparseç”¨)
from qdrant_client_wrapper import embed_sparse_texts_unified
from helper_embedding import get_embedding_dimensions, DEFAULT_EMBEDDING_PROVIDER

logger = logging.getLogger(__name__)


def show_qdrant_registration_page():
    """ç”»é¢: CSVãƒ‡ãƒ¼ã‚¿ç™»éŒ²"""
    st.title("ğŸ“¥ CSVãƒ‡ãƒ¼ã‚¿ç™»éŒ²")
    st.caption("qa_output/*.csvã®ãƒ‡ãƒ¼ã‚¿ã‚’Qdrantãƒ™ã‚¯ãƒˆãƒ«DBã«ç™»éŒ²ã—ã¾ã™")

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šè¨­å®š
    with st.sidebar:
        st.header("âš™ï¸ Qdrantè¨­å®š")

        qdrant_url = st.text_input(
            "Qdrant URL", value="http://localhost:6333", help="Qdrantã‚µãƒ¼ãƒãƒ¼ã®URL"
        )

    # Qdrantæ¥ç¶šç¢ºèª
    qdrant_connected = False
    try:
        client = QdrantClient(url=qdrant_url, timeout=30)
        # æ¥ç¶šãƒ†ã‚¹ãƒˆ
        client.get_collections()
        qdrant_connected = True
    except Exception as e:
        st.error(f"âŒ Qdrantæ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
        st.warning("QdrantãŒèµ·å‹•ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        st.code("docker run -p 6333:6333 qdrant/qdrant", language="bash")
        client = None

    st.divider()

    if not qdrant_connected:
        st.warning("Qdrantã«æ¥ç¶šã§ãã¦ã„ã¾ã›ã‚“ã€‚è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return

    # ===================================================================
    # CSVç™»éŒ²è¨­å®š
    # ===================================================================
    st.subheader("ğŸ“„ ç™»éŒ²è¨­å®š")

    # qa_output/*.csvãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§å–å¾—
    qa_output_dir = Path("qa_output")
    if qa_output_dir.exists():
        csv_files = sorted(qa_output_dir.glob("*.csv"))
        csv_options = [f.name for f in csv_files]
    else:
        csv_options = []

    if not csv_options:
        st.warning("qa_output/ãƒ•ã‚©ãƒ«ãƒ€ã«CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“")
        st.info("å…ˆã«ã€ŒQ/Aç”Ÿæˆã€ã§ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã—ã¦ãã ã•ã„")
        return

    col_setting1, col_setting2 = st.columns(2)

    with col_setting1:
        selected_csv = st.selectbox(
            "ãƒ•ã‚¡ã‚¤ãƒ«é¸æŠ",
            options=csv_options,
            help="ç™»éŒ²ã™ã‚‹CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠ",
        )

        # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³åã‚’è‡ªå‹•ç”Ÿæˆï¼ˆã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºå¯èƒ½ï¼‰
        default_collection = f"qa_{Path(selected_csv).stem}"
        collection_name = st.text_input(
            "ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å",
            value=default_collection,
            help="Qdrantã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³å",
        )

        # ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³åã®ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
        is_valid_collection_name = bool(re.fullmatch(r"^[a-zA-Z0-9_-]+$", collection_name))
        if not is_valid_collection_name:
            st.error("ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³åã«ã¯åŠè§’è‹±æ•°å­—ã€ã‚¢ãƒ³ãƒ€ãƒ¼ã‚¹ã‚³ã‚¢(_) ã€ãƒã‚¤ãƒ•ãƒ³(-)ã®ã¿ä½¿ç”¨ã§ãã¾ã™ã€‚")

    with col_setting2:
        recreate_collection = st.checkbox(
            "æ—¢å­˜ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãŒã‚ã‚Œã°ä¸Šæ›¸ãã™ã‚‹",
            value=True,
            help="åŒåã®ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ãŒå­˜åœ¨ã™ã‚‹å ´åˆã€å‰Šé™¤ã—ã¦æ–°è¦ä½œæˆã—ã¾ã™ï¼ˆãƒã‚§ãƒƒã‚¯ã‚’å¤–ã™ã¨è¿½åŠ ç™»éŒ²ã«ãªã‚Šã¾ã™ï¼‰",
        )

        include_answer = st.checkbox(
            "answerã‚’å«ã‚ã‚‹ï¼ˆæ¨å¥¨ï¼‰", 
            value=True, 
            help="åŸ‹ã‚è¾¼ã¿ç”Ÿæˆæ™‚ã«è³ªå•ã ã‘ã§ãªãå›ç­”ã‚‚å«ã‚ã‚‹ã“ã¨ã§ã€æ¤œç´¢ç²¾åº¦ãŒå‘ä¸Šã™ã‚‹å ´åˆãŒã‚ã‚Šã¾ã™"
        )

        data_limit = st.number_input(
            "ãƒ‡ãƒ¼ã‚¿ä»¶æ•°åˆ¶é™ (0=ç„¡åˆ¶é™)",
            min_value=0,
            max_value=100000,
            value=0,
            step=100,
            help="ãƒ†ã‚¹ãƒˆç”¨ã«ç™»éŒ²ä»¶æ•°ã‚’åˆ¶é™ã™ã‚‹å ´åˆã«ä½¿ç”¨ã—ã¾ã™",
        )
        
        use_hybrid_search = st.checkbox(
            "Hybrid Search (Sparse Vector) ã‚’æœ‰åŠ¹ã«ã™ã‚‹",
            value=True,
            help="ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢ç”¨ã®Sparse Vectorã‚‚ç”Ÿæˆãƒ»ç™»éŒ²ã—ã¾ã™ï¼ˆæ¤œç´¢ç²¾åº¦ãŒå‘ä¸Šã—ã¾ã™ï¼‰"
        )

    # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±è¡¨ç¤º
    csv_path = qa_output_dir / selected_csv
    file_size = csv_path.stat().st_size
    if file_size < 1024:
        size_str = f"{file_size} B"
    elif file_size < 1024 * 1024:
        size_str = f"{file_size / 1024:.1f} KB"
    else:
        size_str = f"{file_size / (1024 * 1024):.1f} MB"

    st.info(f"é¸æŠä¸­: **{selected_csv}** ({size_str}) -> ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³: **{collection_name}**")

    # ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
    with st.expander("ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆæœ€åˆã®3ä»¶ï¼‰"):
        try:
            df_preview = pd.read_csv(csv_path, nrows=3)
            st.dataframe(df_preview, width='stretch')
        except Exception as e:
            st.error(f"ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

    st.divider()

    # APIè²»ç”¨ç¯€ç´„ã®ãŸã‚ã®èª¬æ˜ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆãƒ”ãƒ³ã‚¯èƒŒæ™¯ï¼‰
    pink_message_html = """
    <div style="background-color:#FFC0CB; padding:10px; border-radius:5px; border:1px solid #FF69B4;">
        <p style="color:#8B0000; font-weight:bold; margin-bottom:0px;">
            ã™ã§ã«ã€HuggingFaceã‹ã‚‰ä¸‹è¨˜ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦é…ç½®ã€<br>
            Q/Aãƒšã‚¢ã‚’ä½œæˆæ¸ˆã¿ã€Qdrantã«embeddingãƒ™ã‚¯ãƒˆãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’ç™»éŒ²æ¸ˆã¿ã§ã™ã€‚<br>
            ãƒ»Wikipediaæ—¥æœ¬èªç‰ˆ<br>
            ãƒ»æ—¥æœ¬èªWebãƒ†ã‚­ã‚¹ãƒˆï¼ˆCC100ï¼‰<br>
            ãƒ»CC-Newsï¼ˆè‹±èªãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼‰<br>
            ãƒ»Livedoorãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‘ã‚¹<br>
            ã‚ˆã£ã¦ã€ã“ã“ã®é€ä¿¡ãƒœã‚¿ãƒ³ã¯disableã«ã—ã¦ã‚ã‚Šã¾ã™ã€‚ï¼ˆAPIè²»ç”¨ãŒã‹ã‹ã‚Šéãã‚‹ã®ã§ğŸ˜¹ï¼‰
        </p>
    </div>
    """
    st.markdown(pink_message_html, unsafe_allow_html=True)
    st.write("") # 1è¡Œç©ºã‘ã‚‹

    # ç™»éŒ²ãƒœã‚¿ãƒ³
    run_registration = st.button(
        "ğŸš€ Qdrantã«ç™»éŒ²ã‚’å®Ÿè¡Œ",
        type="primary",
        width='stretch',
        disabled=True, # not (qdrant_connected and is_valid_collection_name),
    )

    # ãƒ­ã‚°è¡¨ç¤ºã‚¨ãƒªã‚¢
    st.subheader("ğŸ“œ å‡¦ç†ãƒ­ã‚°")
    log_container = st.container()

    if "qdrant_registration_logs" not in st.session_state:
        st.session_state["qdrant_registration_logs"] = []

    def add_log(message: str):
        """ãƒ­ã‚°ã‚’è¿½åŠ """
        timestamp = datetime.now().strftime("%H:%M:%S")
        st.session_state["qdrant_registration_logs"].append(f"[{timestamp}] {message}")

    # ç™»éŒ²å‡¦ç†å®Ÿè¡Œ
    if run_registration:
        st.session_state["qdrant_registration_logs"] = []  # ãƒ­ã‚°ã‚¯ãƒªã‚¢
        add_log(f"ğŸš€ ç™»éŒ²å‡¦ç†é–‹å§‹: {selected_csv}")

        try:
            # ã‚¹ãƒ†ãƒƒãƒ—1: CSVãƒ­ãƒ¼ãƒ‰
            with st.spinner("ğŸ“ CSVãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ä¸­..."):
                add_log(f"ğŸ“ CSVèª­ã¿è¾¼ã¿: {csv_path}")
                df = load_csv_for_qdrant(str(csv_path), limit=data_limit)
                add_log(f"âœ… {len(df)} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")

            # ã‚¹ãƒ†ãƒƒãƒ—2: ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³ä½œæˆ
            with st.spinner("ğŸ—„ï¸ ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æº–å‚™ä¸­..."):
                add_log(f"ğŸ—„ï¸ ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æº–å‚™: {collection_name}")
                
                # æ¬¡å…ƒæ•°ã‚’ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã‹ã‚‰å–å¾—
                vector_size = get_embedding_dimensions(DEFAULT_EMBEDDING_PROVIDER)
                
                create_or_recreate_collection_for_qdrant(
                    client, 
                    collection_name, 
                    recreate_collection,
                    vector_size=vector_size,
                    use_sparse=use_hybrid_search
                )
                add_log(f"âœ… ã‚³ãƒ¬ã‚¯ã‚·ãƒ§ãƒ³æº–å‚™å®Œäº† (Sparse: {use_hybrid_search})")

            # ã‚¹ãƒ†ãƒƒãƒ—3: åŸ‹ã‚è¾¼ã¿ç”Ÿæˆ (Dense)
            with st.spinner("ğŸ”¢ DenseåŸ‹ã‚è¾¼ã¿ç”Ÿæˆä¸­..."):
                add_log("ğŸ”¢ DenseåŸ‹ã‚è¾¼ã¿ç”Ÿæˆé–‹å§‹")
                texts = build_inputs_for_embedding(df, include_answer)
                vectors = embed_texts_for_qdrant(
                    texts, model="gemini-embedding-001" # modelå¼•æ•°ã¯äº’æ›æ€§ã®ãŸã‚æ®‹ã‚‹ãŒå†…éƒ¨ã§providerä½¿ç”¨
                )
                add_log(f"âœ… {len(vectors)} ä»¶ã®DenseåŸ‹ã‚è¾¼ã¿ã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
            
            # ã‚¹ãƒ†ãƒƒãƒ—3.5: SparseåŸ‹ã‚è¾¼ã¿ç”Ÿæˆ
            sparse_vectors = None
            if use_hybrid_search:
                with st.spinner("ğŸ”  SparseåŸ‹ã‚è¾¼ã¿ç”Ÿæˆä¸­ (FastEmbed)..."):
                    add_log("ğŸ”  SparseåŸ‹ã‚è¾¼ã¿ç”Ÿæˆé–‹å§‹ (FastEmbed)")
                    
                    # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã®ä½œæˆ
                    progress_bar = st.progress(0, text="Sparse Embedding ç”Ÿæˆä¸­...")
                    
                    def update_progress(current, total):
                        percent = int((current / total) * 100)
                        progress_bar.progress(percent, text=f"Sparse Embedding ç”Ÿæˆä¸­... ({current}/{total})")
                    
                    try:
                        sparse_vectors = embed_sparse_texts_unified(
                            texts, 
                            progress_callback=update_progress
                        )
                    finally:
                        progress_bar.empty()
                        
                    add_log(f"âœ… {len(sparse_vectors)} ä»¶ã®SparseåŸ‹ã‚è¾¼ã¿ã‚’ç”Ÿæˆã—ã¾ã—ãŸ")

            # ã‚¹ãƒ†ãƒƒãƒ—4: ãƒã‚¤ãƒ³ãƒˆæ§‹ç¯‰
            with st.spinner("ğŸ“¦ ãƒã‚¤ãƒ³ãƒˆæ§‹ç¯‰ä¸­..."):
                add_log("ğŸ“¦ Qdrantãƒã‚¤ãƒ³ãƒˆæ§‹ç¯‰ä¸­")
                # ãƒ‰ãƒ¡ã‚¤ãƒ³åã‚’æ¨å®š
                if "cc_news" in selected_csv.lower():
                    domain = "cc_news"
                elif "livedoor" in selected_csv.lower():
                    domain = "livedoor"
                else:
                    domain = "custom"

                points = build_points_for_qdrant(
                    df, 
                    vectors, 
                    domain, 
                    selected_csv,
                    sparse_vectors=sparse_vectors
                )
                add_log(f"âœ… {len(points)} å€‹ã®ãƒã‚¤ãƒ³ãƒˆã‚’æ§‹ç¯‰ã—ã¾ã—ãŸ")

            # ã‚¹ãƒ†ãƒƒãƒ—5: Qdrantã‚¢ãƒƒãƒ—ã‚µãƒ¼ãƒˆ
            with st.spinner("â¬†ï¸ Qdrantã‚¢ãƒƒãƒ—ã‚µãƒ¼ãƒˆä¸­..."):
                add_log("â¬†ï¸ Qdrantã«ã‚¢ãƒƒãƒ—ã‚µãƒ¼ãƒˆä¸­")
                count = upsert_points_to_qdrant(client, collection_name, points)
                add_log(f"âœ… {count} ä»¶ã‚’Qdrantã«ç™»éŒ²ã—ã¾ã—ãŸ")

            # å®Œäº†
            add_log("ğŸ‰ å…¨å‡¦ç†å®Œäº†ï¼")
            st.success(f"âœ… {count}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’Qdrantã«ç™»éŒ²ã—ã¾ã—ãŸ")

            # çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
            try:
                stats = get_collection_stats(client, collection_name)
                if stats:
                    st.divider()
                    st.subheader("ğŸ“Š ç™»éŒ²çµæœ")
                    st.json(stats)
            except Exception as e:
                logger.warning(f"çµ±è¨ˆæƒ…å ±å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")

        except Exception as e:
            add_log(f"âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {str(e)}")
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")

    # ãƒ­ã‚°è¡¨ç¤º
    with log_container:
        if st.session_state["qdrant_registration_logs"]:
            log_text = "\n".join(st.session_state["qdrant_registration_logs"])
            st.text_area("å‡¦ç†ãƒ­ã‚°", value=log_text, height=300, disabled=True)
        else:
            st.info("ç™»éŒ²å‡¦ç†ã‚’é–‹å§‹ã™ã‚‹ã¨ã“ã“ã«ãƒ­ã‚°ãŒè¡¨ç¤ºã•ã‚Œã¾ã™")
